<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  
  
    <meta name="description" content="人们常常嘲笑“螳臂当车” 但有时候啊，你并不是驾车的人 正巧是那只，反抗不了的螳螂。">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    
    花谢花开</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>
</html>
<body>
<main class="content">
  <section class="jumbotron">
  <div class="video">
    
      <div class="video-frame">
        <img src="/images/ocean/overlay-hero.png" alt="Decorative image frame">
      </div>
    
    <div class="video-media">
      <video playsinline="" autoplay="" loop="" muted="" data-autoplay=""
             poster="/images/ocean/ocean.png" x5-video-player-type="h5">
        <source src="/images/ocean/ocean.mp4" type="video/mp4">
        <source src="/images/ocean/ocean.ogv" type="video/ogg">
        <source src="/images/ocean/ocean.webm" type="video/webm">
        <p>Your user agent does not support the HTML5 Video element.</p>
      </video>
      <div class="video-overlay"></div>
    </div>
    <div class="video-inner text-center text-white">
      <h1><a href="/">花谢花开</a></h1>
      <p></p>
      <div><img src="/images/hexo-inverted.svg" class="brand" alt="花谢花开"></div>
    </div>
    <div class="video-learn-more">
      <a class="anchor" href="#landingpage"><i class="fe fe-mouse"></i></a>
    </div>
  </div>
</section>

<div id="landingpage">
  <section class="outer">
    <article class="articles">
      
      <h1 class="page-type-title"></h1>
      
        
          <article id="post-ES数据迁移策略（ES系列二）" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2020/07/22/ES数据迁移策略（ES系列二）/">ES数据迁移策略（ES系列二）</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2020/07/22/ES数据迁移策略（ES系列二）/" class="article-date">
  <time datetime="2020-07-22T11:19:32.000Z" itemprop="datePublished">2020-07-22</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/elasticsearch/">elasticsearch</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在上一篇文章<a href="https://juejin.im/post/5f06eb2be51d453480767b88" target="_blank" rel="noopener">初识ES</a>中我们介绍了ES优势、使用场景以及相关的核心概念。这篇文章我们继续探讨如何将数据从Mysql迁移到ES中。</p>
<p>在本文中，Logstash和ES的版本均为7.3</p>
<h2 id="一、全量数据迁移"><a href="#一、全量数据迁移" class="headerlink" title="一、全量数据迁移"></a>一、全量数据迁移</h2><p>在将业务迁移到ES的过程中首先就需要将数据全量迁移到ES中，这是一次性的，在调研的过程中主要考虑了如下几种方案。</p>
<h3 id="1、go-mysql-elasticsearch"><a href="#1、go-mysql-elasticsearch" class="headerlink" title="1、go-mysql-elasticsearch"></a>1、go-mysql-elasticsearch</h3><p>go-mysql-elasticsearch is a service syncing your MySQL data into Elasticsearch automatically. It uses mysqldump to fetch the origin data at first, then syncs data incrementally with binlog.</p>
<p>go-mysql-elasticsearch是一个开源的Mysql -&gt; ES的同步工具，使用mysqldump的方式将数据拉下来，然后同步增加到binlog中来实现数据同步，但是使用这种方式的限制很多，而且基本不怎么维护，所以不建议使用这种方案。</p>
<h3 id="2、ES-BulkRequest"><a href="#2、ES-BulkRequest" class="headerlink" title="2、ES BulkRequest"></a>2、ES BulkRequest</h3><p>ES给我们提供了批量插入的API，我们可以采用在Mysql中分页查询，然后批量插入到ES中，类似下边的代码可以实现这样的功能。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">BulkRequest bulkRequest = <span class="keyword">new</span> BulkRequest(<span class="string">"your index name"</span>);</span><br><span class="line">        <span class="keyword">for</span> (Order item : orderList )&#123;</span><br><span class="line">            Map&lt;String, Object&gt; itemMap = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">16</span>);</span><br><span class="line">            itemMap.put(id, item.getId());</span><br><span class="line">            itemMap.put(orderCode, item.getOrderCode());</span><br><span class="line">            itemMap.put(orderName, item.getOrderName());</span><br><span class="line">            bulkRequest.add(<span class="keyword">new</span> IndexRequest(<span class="string">"your index name"</span>).id(item.getId().toString()).source(itemMap));</span><br><span class="line">        &#125;</span><br><span class="line">        BulkResponse bulkResponse;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            bulkResponse = remoteHighLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            log.error(<span class="string">"Insert batch execution failed: &#123;&#125;"</span>, e.getMessage(), e);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>通过这种方式也是可以实现全量同步的，但是问题是<strong>执行批量插入的速度太慢</strong>，若我们的数据达到上千万级，同步的时间将会非常漫长。</p>
<h3 id="3、阿里云DTS"><a href="#3、阿里云DTS" class="headerlink" title="3、阿里云DTS"></a>3、阿里云DTS</h3><p>若是生产环境均购买阿里云的ELK服务，可以考虑使用DTS服务来实现Mysql和ES的数据同步，DTS的全量同步原理架构图如下：<br><img src="https://res.cloudinary.com/leon824/image/upload/v1595426140/es4_lqfyib.png" alt><br>注：图片来自<a href="https://help.aliyun.com/document_detail/26598.html?spm=a2c4g.11186623.6.550.79f51797WZSaOm" target="_blank" rel="noopener">阿里云官方</a></p>
<p><strong>DTS实现了在全量同步的时候可以不停服</strong>，在全量数据迁移之前会启动增量数据拉取模块，增量数据拉取模块会拉取源实例的增量更新数据，并解析、封装、存储在本地存储中。当全量数据迁移完成后，DTS会启动增量日志回放模块，增量日志回放模块会从增量日志读取模块中获取增量数据，经过反解析、过滤、封装后迁移到目标实例，从而实现增量数据迁移。</p>
<p>但是DTS截止目前对于ES的支持仅限在&lt;=6.7，而我们使用的是<code>ES7.3</code>版本，所以这种方式也暂时不考虑。</p>
<h3 id="4、Logstash"><a href="#4、Logstash" class="headerlink" title="4、Logstash"></a>4、Logstash</h3><p>排除了上边三种方案之后，看似只剩下logstash能满足我们目前的需求了。Logstash是ELK技术栈的重要组成部分，Logstash是开源的、拥有实时管道处理能力的数据收集引擎。input模块支持多种输入源（kafka、mysql、filebeat等等），filter模块支持正则、ruby等等工具来实现强大的数据过滤，数据类型转换等等功能，最终将管道处理完成的数据用output模块输出到指定的目的地。在这里我们使用<a href="https://www.elastic.co/guide/en/logstash/7.4/plugins-inputs-jdbc.html" target="_blank" rel="noopener">Jdbc input plugin</a>来实现对Mysql的查询、ES作为最终的输出目的地来实现全量数据的迁移，先来看Logstash官方对它的描述：</p>
<p>“Description This plugin was created as a way to ingest data in any database with a JDBC interface into Logstash. You can periodically schedule ingestion using a cron syntax (see schedule setting) or run the query one time to load data into Logstash. Each row in the resultset becomes a single event. Columns in the resultset are converted into fields in the event.”</p>
<p>大意就是这个插件会创建一种方式，用jdbc接口从任何数据库中拉取数据到logstash，我们可以使用<code>cron</code>的方式定期拉取数据，或执行一次查询将数据加载到Logstash。</p>
<p>先来看一个Logstash的管道配置。</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  jdbc &#123;</span><br><span class="line">    jdbc_driver_library =&gt; <span class="string">"/opt/soft/mysql-connector-java-5.1.45.jar"</span> </span><br><span class="line">    jdbc_driver_class =&gt; <span class="string">"com.mysql.jdbc.Driver"</span></span><br><span class="line">    jdbc_connection_string =&gt; <span class="string">"jdbc:mysql://localhost:3306/database_name"</span></span><br><span class="line">    jdbc_user =&gt; <span class="string">"root"</span></span><br><span class="line">    jdbc_password =&gt; <span class="string">"**************"</span></span><br><span class="line">    jdbc_paging_enabled =&gt; <span class="literal">true</span></span><br><span class="line">    jdbc_page_size =&gt; <span class="number">10000</span></span><br><span class="line">    clean_run =&gt; <span class="literal">true</span></span><br><span class="line">    last_run_metadata_path =&gt; <span class="string">"/opt/soft/elk7.3/logstash/.log_last_run"</span></span><br><span class="line">   statement =&gt; <span class="string">"select id, order_code as orderCode, order_name as orderName, create_time as createTime, update_time as updateTime from es_order"</span></span><br><span class="line">    schedule =&gt; <span class="string">"* * * * *"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    copy =&gt; &#123; <span class="string">"id"</span> =&gt; <span class="string">"[@metadata][_id]"</span>&#125;</span><br><span class="line">    remove_field =&gt; [<span class="string">"@version"</span>, <span class="string">"_score"</span>, <span class="string">"_type"</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    user =&gt; admin </span><br><span class="line">    password =&gt; <span class="string">"********"</span> </span><br><span class="line">    index =&gt; <span class="string">"es_order_index"</span></span><br><span class="line">    document_id =&gt; <span class="string">"%&#123;[@metadata][_id]&#125;"</span></span><br><span class="line">    hosts =&gt; [<span class="string">"http://localhost:9200"</span>]</span><br><span class="line">  &#125;</span><br><span class="line">  stdout&#123;</span><br><span class="line">  codec =&gt; rubydebug</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上边的管道配置中，有下面几个地方需要注意：</p>
<h4 id="input模块"><a href="#input模块" class="headerlink" title="input模块"></a>input模块</h4><ul>
<li><strong>jdbc_driver_library</strong>：指定的Mysql驱动，一般来说是没有问题的，但是若版本采用8.0以上的版本，则可能会出现<strong>迁移全量数据遗漏的问题</strong>，导致总会有一部分数据同步失败，定位迁移失败原因非常麻烦。</li>
<li><strong>jdbc_paging_enabled</strong>：指定开启查询分页</li>
<li><strong>jdbc_page_size</strong>：指定每次分页查询的大小</li>
<li><strong>statement</strong>：我们指定查询语句，Logstash将根据这里的Sql发起查询，若sql较为复杂可以使用<code>statement_filepath</code>参数指定Sql文件的目录。</li>
<li><strong>schedule</strong>：通过设置Cron，Logstash周期性的执行任务，此参数没有默认值，无没有配置，则只执行一次；这里配置的<code>&quot;* * * * *&quot;</code>，代表着每分钟执行一次。</li>
</ul>
<h4 id="filter模块"><a href="#filter模块" class="headerlink" title="filter模块"></a>filter模块</h4><p>这里的过滤模块较为简单，因为Mysql中的数据都是已经结构化的。</p>
<ul>
<li><strong>copy</strong>：在ES中每一个文档（概念在上一篇已经讲过了），是由<code>index</code>、<code>_type</code>、<code>_id</code>三个参数共同标识的，所以每一个文档必须拥有一个_id作为<code>metadata</code>，在这里我们<strong>使用<code>Mysql</code>的主键复制到ES中的_id字段</strong>，方便我们在使用后边的增删改查。否则，则ES会自动生成一个Base64的字符串赋值给<code>_id</code>。</li>
<li><strong>remove_field</strong>：这里可以指定我们要删除的的字段</li>
</ul>
<h4 id="output模块"><a href="#output模块" class="headerlink" title="output模块"></a>output模块</h4><ul>
<li><strong>document_id =&gt; “%{[@metadata][_id]}</strong>“：这一行即是将我们在filter模块中复制主键id的值提取出来设置到document_id中。</li>
<li><strong>codec =&gt; rubydebug</strong>：在测试阶段，我们将Logstash的执行日志打印出来。</li>
</ul>
<p>在配置完成后，我们可以在启动的时候通过指定刚刚创建的管道来实现全量迁移。经过测试和生产环境的测试，迁移五百万数据大概在二十分钟左右，但是在生产数据迁移的过程中使用这种方式需要将迁移表写入、修改操作停止。为了避免停止整个服务，可以在配置中心配置开关来控制数据的写入，迁移完成之后打开，以减小对业务的影响。</p>
<h2 id="二、增量数据同步"><a href="#二、增量数据同步" class="headerlink" title="二、增量数据同步"></a>二、增量数据同步</h2><p>在上一部分，我们探讨了如何对数据的全量迁移，这里我们接着探讨如何实现对增量数据的同步。这里实质上就是想实现Mysql-ES的数据一致性，我们知道数据一致性大致分为两种，一种是强一致性，一种是最终一致性。</p>
<h3 id="1、强一致性实现"><a href="#1、强一致性实现" class="headerlink" title="1、强一致性实现"></a>1、强一致性实现</h3><p>在分布式系统中，若要实现强一致性，往往会牺牲较多的性能来实现，比如这里我们可以采用“<strong>同步双写</strong>”来实现事务。当有写入请求进来时，我们先写入到ES中，ES写入失败则此次插入失败，或者重新发起请求写入；待ES写入成功之后，再写Mysql，成功则事务完成，反之需要回滚ES已经写入的内容，否则双方数据将出现不一致。<br>从上边的流程来看，可能涉及到的远程调用较多、网络IO将拖慢接口的响应速度，使得系统吞吐量降低…所以想实现强一致性成本是比较高的，下面我们再来看看实现最终一致性的方案。</p>
<h3 id="2、最终一致性"><a href="#2、最终一致性" class="headerlink" title="2、最终一致性"></a>2、最终一致性</h3><p>实现最终一致性的方案之间也有较大的区分。下边主要介绍两种方式来实现：异步MQ同步、储存层面实现最终一致性</p>
<h4 id="a、异步MQ同步"><a href="#a、异步MQ同步" class="headerlink" title="a、异步MQ同步"></a>a、异步MQ同步</h4><p>方案描述：假设业务入口在微服务A中，对ES的封装在微服务B中，如下图:</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1595492799/es-3_gnvfgz.png" alt></p>
<ul>
<li>1、业务请求到A服务中，若有对数据的写，先写入到Mysql中，然后将写的<strong>动作和data</strong>扔到MQ。</li>
<li>2、B服务监听对应的<code>Topic</code>，根据“<strong>相应的动作</strong>”对ES发起写请求</li>
<li>3、若写入失败，B服务将发起重试消费（可设置重试<em>上限次数</em>），直到成功。</li>
<li>4、若重试次数超过上限，则发起报警，我们可以触发业务补偿来实现数据最终一致性。</li>
</ul>
<p>上述的方案通过异步的方式将数据一致性的压力从A服务转移给B服务，从而最大程度降低对A服务性能的影响。</p>
<h4 id="b、储存层面实现最终一致性"><a href="#b、储存层面实现最终一致性" class="headerlink" title="b、储存层面实现最终一致性"></a>b、储存层面实现最终一致性</h4><p>在分布式领域，数据一致性若是能够在存储层面来解决是相对理想的情况，业务不参与数据一致性的工作，对于业务方来说读Mysql和ES永远都能拿到一样的结果，当然这是一种理想状态。<br>现实中我们可以使用Logstash来实现数据的同步，从而数据一致性对于业务来说是透明的，但是由于资源的限制，我们无法做到<strong>完全Real-time</strong>。</p>
<h4 id="c、Logstash增量同步"><a href="#c、Logstash增量同步" class="headerlink" title="c、Logstash增量同步"></a>c、Logstash增量同步</h4><p>在前边全量数据迁移的部分我们已经使用Logstash来实现了，在增量同步同样可以使用这种方式，来来看增量同步的管道脚本。</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  jdbc &#123;</span><br><span class="line">    jdbc_driver_library =&gt; <span class="string">"/opt/soft/mysql-connector-java-5.1.47.jar"</span></span><br><span class="line">    jdbc_driver_class =&gt; <span class="string">"com.mysql.jdbc.Driver"</span></span><br><span class="line">    jdbc_connection_string =&gt; <span class="string">"jdbc:mysql://localhost:3306/database_name"</span></span><br><span class="line">    jdbc_user =&gt; <span class="string">"root"</span></span><br><span class="line">    jdbc_password =&gt; <span class="string">"********"</span></span><br><span class="line">    tracking_column =&gt; <span class="string">"unix_ts_in_secs"</span></span><br><span class="line">    use_column_value =&gt; <span class="literal">true</span></span><br><span class="line">    tracking_column_type =&gt; <span class="string">"numeric"</span></span><br><span class="line">    clean_run =&gt; <span class="literal">true</span></span><br><span class="line">    statement =&gt; <span class="string">"id, order_code as orderCode, order_name as orderName, create_time as createTime, update_time as updateTime, UNIX_TIMESTAMP(update_time) AS unix_ts_in_secs FROM es_order WHERE (UNIX_TIMESTAMP(update_time) &gt; :sql_last_value AND update_time &lt; NOW()) ORDER BY update_time ASC"</span></span><br><span class="line">    schedule =&gt; <span class="string">"*/30 * * * * *"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">  mutate &#123;</span><br><span class="line">    copy =&gt; &#123;<span class="string">"id"</span> =&gt; <span class="string">"[@metadata][_id]"</span>&#125;</span><br><span class="line">    remove_field =&gt; [<span class="string">"@version"</span>, <span class="string">"unix_ts_in_secs"</span>, <span class="string">"myid"</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    index =&gt; <span class="string">"es_order_index"</span></span><br><span class="line">    document_id =&gt; <span class="string">"%&#123;[@metadata][_id]&#125;"</span></span><br><span class="line">    user =&gt; admin</span><br><span class="line">    password =&gt; <span class="string">"**********"</span></span><br><span class="line">    hosts =&gt; [<span class="string">"http://localhost:9200"</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上一部分我们已经分析了一部分参数的含义，这里我们接着看新出现的属性值</p>
<ul>
<li><p><strong>tracking_column</strong>：用于跟踪Logstash从MySQL读取的最后一个文档，下面会进行描述），它存储在.logstash_jdbc_last_run中的磁盘上。该值将会用来确定Logstash在其轮询循环的下一次迭代中所请求文档的起始值。</p>
</li>
<li><p><strong>unix_ts_in_secs：<code>unix_ts_in_secs</code></strong>：这是一个由上述 SELECT 语句生成的字段，包含可作为标准<code>Unix</code>时间戳（自Epoch起秒数）的 “modification_time”。我们刚讨论的 “tracking column” 会引用该字段。Unix 时间戳用于跟踪进度，而非作为简单的时间戳；如将其作为简单时间戳，可能会导致错误，因为在UMTs和本地时区之间正确地来回转换是一个十分复杂的过程。</p>
</li>
<li><strong>sql_last_value</strong>：这是一个内置参数，包括Logstash轮询循环中当前迭代的起始点，上面 JDBC 输入配置中的 SELECT 语句便会引用这一参数。该字段会设置为“unix_ts_in_secs”（读取自 .logstash_jdbc_last_run）的最新值。在<code>Logstash</code>轮询循环内所执行的<code>MySQL</code>查询中，其会用作所返回文档的起点。通过在查询中加入这一变量，能够确保不会将之前传播到<code>Elasticsearch</code>的插入或更新内容重新发送到<code>Elasticsearch</code>。</li>
<li><strong>modification_time &lt; NOW()</strong>：查询语句中的这一部分是一个较难解释的概念。</li>
</ul>
<p>注：引用自<a href="https://www.elastic.co/cn/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash" target="_blank" rel="noopener">这里</a> </p>
<p>对于SQL语句的正确性分析，在上边引用的文章已经有比较详细的描述，这里不再重述。</p>
<p>这种方案的问题在于——<strong>特别吃资源</strong>，特别是如果<code>schedule</code>设置的定时执行时间间隔太短并且有多个表需要同步的情况下，由于这种Sql属于<strong>范围区间查询同时带有排序，无法让查询走索引</strong>，所以Mysql将会承受很大的压力。所以大家在选择这种方案的时候必须心中有数，虽然解放了应用层，但是数据存储层将会承受较大的压力。</p>
<h4 id="d、Binlog增量同步"><a href="#d、Binlog增量同步" class="headerlink" title="d、Binlog增量同步"></a>d、Binlog增量同步</h4><p>这种类型的方案更加适合数据的增量同步，它同时能够避免上述两种方案的问题：1、业务参与解决数数据一致性，2、对存储源压力过大。</p>
<h5 id="Canal"><a href="#Canal" class="headerlink" title="Canal"></a>Canal</h5><p>canal是阿里开源的组件，它是基于MySQL数据库增量日志解析，提供增量数据订阅和消费，消费端其中就包括ES。如下图</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1595574185/es-7_t20xku.png" alt></p>
<p>这种方案暂时还没有使用过，感兴趣的小伙伴可以自己尝试地址在这儿<a href="https://github.com/alibaba/canal/wiki" target="_blank" rel="noopener">Home</a></p>
<h5 id="DTS"><a href="#DTS" class="headerlink" title="DTS"></a>DTS</h5><p>在上边的全量数据迁移也提到过这种方案，和Canal一样都是使用Binlog的方式来实现。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我们先介绍了全量数据同步的方式，包括使用go-mysql-elasticsearch、ES BulkRequest、阿里云DTS和Logstash的方式，这里<strong>最推荐的还是Logstash来实现全量同步</strong>，当然有条件的可以使用DTS来实现。</p>
<p>后边我们探讨实现增量同步的集中方法，增量同步我们分为强一致性和最终一致性，强一致性实现成本相对较高；我们主要分析了最终一致性的几种方式，若是数据库资源较为充裕，可以考虑使用Logstash来实现增量同步，否则可以采用异步MQ的方式来实现，大家可以根据自己的实际情况来选择增量的同步方式。</p>
<p>下一部分我们继续分享如何使用<code>Java High Level REST Client</code>来实现对ES的操作。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://help.aliyun.com/document_detail/26598.html?spm=a2c4g.11186623.6.550.79f51797WZSaOm" target="_blank" rel="noopener">产品架构及功能原理</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html" target="_blank" rel="noopener">Elasticsearch Reference [7.8] » REST APIs » Document APIs » Bulk API</a></li>
<li><a href="https://www.elastic.co/cn/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash" target="_blank" rel="noopener">如何使用 Logstash 和 JDBC 确保 Elasticsearch 与关系型数据库保持同步</a></li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2020/07/22/ES数据迁移策略（ES系列二）/" data-id="ckczxj13g0000buyn8djrvhca" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-ES系列（一）" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2020/07/22/ES系列（一）/">初识ES（ES系列一）</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2020/07/22/ES系列（一）/" class="article-date">
  <time datetime="2020-07-22T07:22:37.000Z" itemprop="datePublished">2020-07-22</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote>
<p>“这个世界已然被数据淹没。多年来，我们系统间流转和产生的大量数据已让我们不知所措。 现有的技术都集中在如何解决数据仓库存储以及如何结构化这些数据。 这些看上去都挺美好，直到你实际需要基于这些数据实时做决策分析的时候才发现根本不是那么一回事。Elasticsearch是一个<strong>分布式、可扩展、实时的搜索与数据分析引擎</strong>。无论你是需要<strong>全文搜索</strong>，还是<strong>结构化数据的实时统计</strong>，或者两者结合，Elasticsearch不仅仅只是全文搜索，我们还将介绍<strong>结构化搜索、数据分析、复杂的人类语言处理、地理位置和对象间关联关系</strong>等”。<br>                    – <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/cn/preface.html" target="_blank" rel="noopener">Elasticsearch: 权威指南 » 前言</a></p>
</blockquote>
<p>上边一段摘录自<code>Elasticsearch: 权威指南</code>，告诉了我们ES拥有的超强能力。这个系列文章主要是根据在工作中的实战总结，<strong>最终目的是探讨一下如何根据现有的业务需求平滑的迁移到ES（使用java技术栈），去弥补关系型数据库的局限性，提高我们的处理数据的能力。</strong></p>
<p>本系列暂时规划为四个部分</p>
<ul>
<li>第一部分：谈谈为什么我们需要使用ES，以及相关基本概念</li>
<li>第二部分：我们讨论Mysql -&gt; ES数据的迁移策略、技术选型，以及在各种场景下选择的同步策略。</li>
<li>第三部分： 我们将实现spring boot与ES的集成，以及使用ES提供的API去“<strong>翻译sql</strong>”</li>
<li>第四部分：我们以前边的技术基础，去尝试解决一个现实中RDBMS单表数据量千万级，同时还有多表join的情况下如何使用ES去解决这个令人头痛的难题。</li>
</ul>
<hr>
<p>话不多说，我们先来看为什么需要使用ES。</p>
<h2 id="一、为什么需要-Elasticsearch"><a href="#一、为什么需要-Elasticsearch" class="headerlink" title="一、为什么需要 Elasticsearch"></a>一、为什么需要 Elasticsearch</h2><h4 id="1、快，就是快"><a href="#1、快，就是快" class="headerlink" title="1、快，就是快"></a>1、快，就是快</h4><p>我们使用ES最主要的原因就是因为ES速度快。特别是当数据量到达千万级以上的时候，关系型数据库单表无论是通过增加索引、分库分表来优化，最终能够优化的效果往往不如人意（且分库分表复杂度较高），而ES可以轻松hold住千万、亿级数据量。</p>
<p>为了达到这样的速度，ES使用了<strong>有限状态转换器</strong>实现了用于全文检索的<strong>倒排索引</strong>，实现了用于存储数值数据和地理位置数据的<strong>BKD树</strong>，以及用于分析的列存储。并且由于ES默认就是将所有的字段全部建立索引，所以我们在查询的时候可以实时地检索到数据。</p>
<h4 id="2、不只是全文检索"><a href="#2、不只是全文检索" class="headerlink" title="2、不只是全文检索"></a>2、不只是全文检索</h4><p>这一点也是我们使用ES很重要的原因，在传统关系型数据库中，我们很多使用需要采用模糊查询的方式来获取想要的数据。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> author <span class="keyword">where</span> <span class="keyword">name</span> <span class="keyword">like</span> <span class="string">'%鲁迅%'</span>.</span><br></pre></td></tr></table></figure>
<p>在数据量较大的时候，就算我们在name字段上建立索引，上边的SQL也是不会走索引的（不符合最左前缀原则），将执行全表扫描，性能可想而知。<br>但是若在ES中实现上述的查询则很简单，由于ES采用的存储、索引策略，可以实时的查询到想要的结果。</p>
<p>但是这里无论是精确查询还是模糊查询，本质上来时“传统关系型数据库”的思维，ES本质上是一个<strong>搜索、分析引擎</strong>，搜索引擎从一个抽象的角度来讲，它做了三件事：<strong>收集数据、建立数据索引、相关度排名</strong>。在ES中收集数据是有我们来完成的，1、比如将关系型数据库中的数据同步到ES中；2、然后ES将同步的数据建立索引，方便之后的查询；3、最后一步也是最重要的一步，也就是相关度排名，如此大量的数据，不会是所有都拥有相同的重要程度，所以排名的好坏对于搜索引擎来说很重要，它决定了搜索质量的高低。</p>
<p>在ES中也是这样，我们在使用查询的时候不仅仅是将数据查询出来，ES还能将关键词检索到的数据根据<strong>相关度排名</strong>。这也更符合我们人类的思维方式，假设我们使用关键词“鲁迅”不是为了查询所有包含鲁迅关键词的文章、报道。而是希望把大家都认为有关鲁迅这个人最重要的作品、个人背景、人生经历、历史评价等等信息根据相关度排序检索出来。</p>
<p>所以这也是传统关系型数据库不能提供的功能，它”似乎“更能懂得我们真正想要的结果。</p>
<h4 id="3、完整的生态系统"><a href="#3、完整的生态系统" class="headerlink" title="3、完整的生态系统"></a>3、完整的生态系统</h4><p>ElasticSearch是Elastic公司的核心技术栈，他们还包括Logstash、Filebeat、Kibana等等。</p>
<p>我们可以使用ES提供的技术栈，实现各种目的，比如典型的采用ELK + Filebeat搭建一套分布式日志采集系统，将各个微服务的日志通过Filebeat收集推送到Logstash管道做处理，然后logstash推送给ES，最终Kibana展示，查询日志。</p>
<h4 id="4、可扩展性"><a href="#4、可扩展性" class="headerlink" title="4、可扩展性"></a>4、可扩展性</h4><p>对于大多数的数据库而言，通常需要对应用程序进行非常大的改动，才能利用上横向扩容的新增资源。 与之相反的是，ElastiSearch天生就是分布式的 ，在ES集群中，我们可以随时增加、摘除节点，集群将会重新平均分布所有的数据。它知道如何通过管理多节点来提高扩容性和可用性。 这也意味着你的应用无需关注这个问题。</p>
<hr>
<p>当然，任何技术都有其合适的应用场景，<strong>ES不支持事务、同时更适合查多改少</strong>的场景，所以我们在选择技术栈的时候需要注意这些限制。</p>
<h2 id="二、核心概念"><a href="#二、核心概念" class="headerlink" title="二、核心概念"></a>二、核心概念</h2><p>无论我们是在开发、维护ES集群的时候，弄清楚ES中的核心概念都是重要的，下面我们采用“<strong>从小到大</strong>”的方式来介绍ES的核心概念。</p>
<h4 id="1、字段（Fields）"><a href="#1、字段（Fields）" class="headerlink" title="1、字段（Fields）"></a>1、字段（Fields）</h4><p>字段是ES中最小的独立单元数据，每一个字段有自己的数据类型（可以自己定义覆盖ES自动设置的数据类型），我们还可以对单个字段设置是否分析、分词器等等。</p>
<p>核心的数据类型有string、Numeric、DateDate、Boolean、Binary、Range等等，复杂类型有Object、Nested，详细的可以<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html" target="_blank" rel="noopener">参考官方的介绍</a></p>
<h4 id="2、文档（Documents）"><a href="#2、文档（Documents）" class="headerlink" title="2、文档（Documents）"></a>2、文档（Documents）</h4><p>在ES中文档的概念相当于RDBMS中的一行数据，不同的是在ES中文档的存储是直接使用json格式存储的（也就是可以嵌套），而不是像RDBMS中把数据”压平”了存储，这一点也是Nosql和关系型数据库比较大的区别。</p>
<p>下面是一个文档的例子</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">"_id"</span>: <span class="number">3</span>,</span><br><span class="line">   “_type”: [“your index type”],</span><br><span class="line">   “_index”: [“your index name”],</span><br><span class="line">   "_source":&#123;</span><br><span class="line">   "age": 28,</span><br><span class="line">   "name": ["daniel”],</span><br><span class="line">   "year":1989,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3、映射（Mapping）"><a href="#3、映射（Mapping）" class="headerlink" title="3、映射（Mapping）"></a>3、映射（Mapping）</h4><p>”Mapping is the process of defining how a document, and the fields it contains, are stored and indexed.“</p>
<p>也就是Mapping是定义文档和字段如何存储和索引，使用Mapping可以定义下面这些信息</p>
<ul>
<li>哪些字段应该作为全文索引</li>
<li>哪些字段包括numbers, dates, geolocations.</li>
<li>时间类型的格式</li>
<li>定义规则控制动态增加字段的mapping</li>
</ul>
<h4 id="4、索引（Index）"><a href="#4、索引（Index）" class="headerlink" title="4、索引（Index）"></a>4、索引（Index）</h4><p>在ES中是最大的数据存储概念，<strong>它是由许多具有相同特征的文档组成的一个集合</strong>。 由于在ES7.0之后逐渐废除Type类型，所以Index从”<strong>数据库</strong>“的概念变成了<em>实际上</em>的”<strong>表</strong>“概念，我们可以把它近似地当成RDBMS中的表，但是要注意Index只是一个逻辑上的概念，真实的数据是分开存储在各个分片中的。</p>
<h4 id="5、分片（Shards）"><a href="#5、分片（Shards）" class="headerlink" title="5、分片（Shards）"></a>5、分片（Shards）</h4><p>这里需要多说几句，搞清楚分片对于理解ES集群（扩容、容错、路由）原理是很重要的。</p>
<p>首先，每个分片都是一个Lucene索引实例，我们可以将其视作一个独立的搜索引擎，它能够对Elasticsearch集群中的数据子集进行索引并处理相关查询。</p>
<p>分片分为两种：<strong>主分片（Primary Shard）、副本分片（Replica Shard）</strong></p>
<ul>
<li><p>主分片：由于所有的数据都会在主分片中存储，所以<strong>主分片决定了文档存储数量的上限</strong>，但是一个索引的主分片数在创建时一旦指定，那么主分片的数量就不能改变，这是因为当索引一个文档时，它是通过其主键（默认）Hash到对应的主分片上（类似于RDBMS分库分表路由策略），所以我们一旦修改主分片数量，那么将无法定位到具体的主分片上。在mapping时我们可以设置<code>number_of_shards</code>值，最大值默认为1024。当然这不是绝对的，如果实在想扩容咋办呢？答案是我们可以重新创建一个索引，然后将老索引的数据迁移到新的索引上，ES为了提供了方法<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/docs-reindex.html" target="_blank" rel="noopener">Reindex API</a></p>
</li>
<li><p>副本分片：我们可以为一个主分片根据实际的硬件资源指定任意数量的副本分片，上边已经说过，每个分片都可以处理查询，所以我们可以<strong>增加副本分片的资源（相应硬件资源提升）来提升系统的处理能力</strong>。同样，在mapping时，可以通过<code>number_of_replicas</code>参数来设置每个主分片的副本分片数量</p>
</li>
</ul>
<p>但是要注意，为了容错（节点主机宕机导致数据丢失），<strong>主分片和副本分片不能在同一个节点上，防止节点宕机导致部分数据丢失</strong>。</p>
<h4 id="6、实例和节点（Instances-and-Nodes）"><a href="#6、实例和节点（Instances-and-Nodes）" class="headerlink" title="6、实例和节点（Instances and Nodes）"></a>6、实例和节点（Instances and Nodes）</h4><p> ”A node is a running instance of Elasticsearch which belongs to a cluster”</p>
<p>节点也就是运行的ES实例，它隶属于某一个集群。通常来说，我们在一个服务器上边部署一个节点，但有时候为了测试集群，也可以在单台服务器上启动多个节点来测试。假设当我们启动一个节点想加入已经存在的一个集群中时，可以在配置文件中配置改集群的名称，以及通信的<code>ip + port</code>，ES会自动通过“<strong>单点传送</strong>”的方式来自动发现集群并尝试加入这个集群。</p>
<p>节点分为下面几种类型:</p>
<ul>
<li>Master-eligible node：负责管理和配置集群，例如增加、删除节点相关动作。</li>
<li>Data node：文档实际上就存储在数据节点，负责执行相关的操作， 例如CRUD、搜索、聚合等等操作</li>
<li>Ingest node：用于文档在indexing之前进行预处理</li>
<li>Machine learning node：主要用于机器学习的任务，但是需要<code>Basic License</code>。</li>
</ul>
<p>关于ES节点的详细介绍，可以参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/modules-node.html#modules-node" target="_blank" rel="noopener">官方文档</a></p>
<h4 id="7、集群（Cluster）"><a href="#7、集群（Cluster）" class="headerlink" title="7、集群（Cluster）"></a>7、集群（Cluster）</h4><ul>
<li>在ES中，集群是由<strong>一个或多个ES节点组成</strong>的，每个集群都有一个唯一的名称/标识符，用作节点加入集群的依据。</li>
<li>每一个集群中有一个Master节点，若是这个Master节点挂了，集群可以用其他的节点代替。<br>在ES中还支持跨集群复制、跨集群检索等等功能，详细的可以参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/xpack-ccr.html#xpack-ccr" target="_blank" rel="noopener">Cross-cluster replication</a>，<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cross-cluster-search.html" target="_blank" rel="noopener">Search across clusters</a></li>
</ul>
<hr>
<p>在上边的两节，我们知道了ES拥有的超强数据处理能力，也了解了ES一些基础的概念。因为网上关于ES使用的倒序索引原理分析已经比较多了，我这里就不在重新描述其中的细节了，具体原理推荐大家一篇文章参考：<a href="https://www.infoq.cn/article/database-timestamp-02" target="_blank" rel="noopener">时间序列数据库的秘密 (2)——索引</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html" target="_blank" rel="noopener">Elasticsearch Reference [7.8] » Mapping</a></p>
</li>
<li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/index-modules.html" target="_blank" rel="noopener">Elasticsearch Reference [7.8] » Index modules</a></p>
</li>
<li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/modules-node.html#modules-node" target="_blank" rel="noopener">Elasticsearch Reference [7.8] » Set up Elasticsearch » Configuring Elasticsearch » Node</a></p>
</li>
<li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/glossary.html#glossary-routing" target="_blank" rel="noopener">Elasticsearch Reference [7.8] » Glossary of terms</a></p>
</li>
<li><p><a href="https://cloud.tencent.com/developer/article/1558616" target="_blank" rel="noopener">Elasticsearch：是什么？你为什么需要他？</a></p>
</li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2020/07/22/ES系列（一）/" data-id="ckczxj13k0001buynry5xsdr7" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-记一次实现日志完整链路追踪（log_trace_id）踩到的坑" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2020/07/14/记一次实现日志完整链路追踪（log_trace_id）踩到的坑/">记一次实现日志完整链路追踪（log_trace_id）踩到的坑</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2020/07/14/记一次实现日志完整链路追踪（log_trace_id）踩到的坑/" class="article-date">
  <time datetime="2020-07-14T07:29:37.000Z" itemprop="datePublished">2020-07-14</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h1 id="记一次实现日志完整链路追踪（log-trace-id）踩到的坑"><a href="#记一次实现日志完整链路追踪（log-trace-id）踩到的坑" class="headerlink" title=" 记一次实现日志完整链路追踪（log_trace_id）踩到的坑"></a><center> 记一次实现日志完整链路追踪（log_trace_id）踩到的坑</center></h1><p></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在分布式环境下，微服务众多、日志分散是一个令人头疼的问题，当然我们可以采用ELK来<strong>将单个微服务的各个容器节点日志汇总到一个索引中来集中查询</strong>，这确实能够提高日志查询的效率。<br>但是，在kiaban中查询日志的时候我们仍然会面对很多的问题，这里就拿三个例子来说明：</p>
<ul>
<li><p>1、[用户请求 -&gt; Gateway -&gt; Microservice]，很多时候Microservice内部还有很多的相互调用，我们如何将一个用户的请求在微服务内部的调用串联起来呢，方便快速定位问题？ELK的架构是无法满足我们这个需求的。</p>
</li>
<li><p>2、MQ也是微服务必备的技术栈，通常producer和consumer不在同一个微服务里，就算在同一个服务里，也不会在同一个线程里。所以，当我们需要追踪某一条消费从生产到消费的完整路径时会比较麻烦。</p>
</li>
<li><p>3、当某一个较大的任务在执行时，我们通常会采用多线程的任务去执行，那么这些多个线程执行的情况我们要如何去串联在一起？方便我们看到整体执行情况 。</p>
</li>
<li><p>4、有时候我们采用@Async注解用异步的方式来运行某些任务，这个异步任务也会运行在一个新的线程中，我们要如何将调用方和异步任务串联起来？</p>
</li>
</ul>
<p>上边描述的三个问题<strong>归根到底就是需要用一个“标识”将一次请求的完整链路全部串联起来</strong>，采用log_trace_ld能够帮助我们来实现全链路追踪。</p>
<h2 id="实现串联微服务"><a href="#实现串联微服务" class="headerlink" title="实现串联微服务"></a>实现串联微服务</h2><p>在前边我们探讨了要使用log_trace_id的原因，所以就开始准备着手解决第一个问题：将微服务内部之间的调用串联起来。</p>
<p>思路如下：</p>
<ul>
<li>1、我们将log_reace_id字段放到Http请求头里边，微服务在接收到请求时，使用拦截器拦截每次请求，若Header中已经存在此字段，则说明此次请求时微服务内部的调用，则继续沿用Header中的log_trace_log，否则重新生成log_trace_id设置到MDC中，代码如下:</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> leon</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2020/7/14</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RequestInterceptor</span> <span class="keyword">extends</span> <span class="title">HandlerInterceptorAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Logger log = LoggerFactory.getLogger(RequestInterceptor.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        log.info(<span class="string">"Enter Interceptor."</span>);</span><br><span class="line">        String traceId = request.getHeader(LOG_TRACE_ID);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(traceId))&#123;</span><br><span class="line">           traceId = UuidUtil.get32UUID();</span><br><span class="line">        &#125;</span><br><span class="line">        MDC.put(LOG_TRACE_ID, traceId);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        MDC.remove(LOG_TRACE_ID);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>2、当微服务发起远程调用的时候，我们还需要将log_trace_id设置到Header中，保持完整调用链使用同一个log_trace_id。因为微服务之间调用全部统一使用Feign来调用，所以这里使用Feign提供的<code>RequestInterceptor</code>拦截器在Feign发起微服务调用之前将参数设置到请求头中。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 当前服务Feign请求拦截器，设置请求头信息</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> leon</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2020/7/14</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFeignRequestInterceptor</span> <span class="keyword">implements</span> <span class="title">RequestInterceptor</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Logger log = LoggerFactory.getLogger(MyFeignRequestInterceptor.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(RequestTemplate template)</span> </span>&#123;</span><br><span class="line">        String traceId = MDC.get(LOG_TRACE_ID);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isNotBlank(traceId))&#123;</span><br><span class="line">            template.header(LOG_TRACE_ID, traceId);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="问题来了"><a href="#问题来了" class="headerlink" title="问题来了"></a>问题来了</h3><ul>
<li>在调试的过程中出现了一个现象，<strong>在有的微服务中<code>String traceId = MDC.get(LOG_TRACE_ID)</code>这行代码是能够拿到traceId的，而有些微服务traceId却为null</strong></li>
</ul>
<h2 id="填坑之路"><a href="#填坑之路" class="headerlink" title="填坑之路"></a>填坑之路</h2><p><strong>在很多时候，我们对某些现象感到疑惑，绝大部分时候说明我们没有认真看文档，没有完整的概念、原理认知才会出现这种情况</strong>。</p>
<p>首先我们需要弄清楚<code>MDC</code>。在上边我们使用<code>MDC</code>(Mapped Diagnostic Context)这个类保存traceId并在Feign请求的时候取出来设置到Header中。简单来说，MDC就是由log4j库提供的一个<code>InheritableThreadLocal&lt;Map&lt;String, String&gt;&gt;</code>对象，我们将traceId设置到这个<code>InheritableThreadLocal</code>中，在同一个线程中/子线程中能够获取到之前我们在拦截器的K-V，同时我们还可以在日志配置文件中pattern中引用当前MDC设置的值<code>%X{log_trace_id}</code>，可以在每行日志中打印traceId对应的值。</p>
<p>通过上边对MDC的描述，我们可以猜测在<code>MyFeignRequestInterceptor</code>拦截类的线程和请求进入的<code>RequestInterceptor</code>拦截器设置traceId并不在同一个线程里。</p>
<p>为了验证想法，我们将线程组的名称、当前线程的ID、name打印出来。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ThreadGroup threadGroup = Thread.currentThread().getThreadGroup();</span><br><span class="line">Thread thread = Thread.currentThread();</span><br><span class="line">log.info(<span class="string">"RequestInterceptor current thread group name: &#123;&#125;, current thread name: &#123;&#125; , id: &#123;&#125;"</span>, threadGroup.getName(), thread.getName(), thread.getId());</span><br><span class="line">        </span><br><span class="line">ThreadGroup threadGroup = Thread.currentThread().getThreadGroup();</span><br><span class="line">Thread thread = Thread.currentThread();</span><br><span class="line">log.info(<span class="string">"MyFeignRequestInterceptor current thread group: &#123;&#125;, name: &#123;&#125; , id: &#123;&#125;"</span>, threadGroup.getName(), thread.getName(), thread.getId());</span><br></pre></td></tr></table></figure>
<p>上边日志打印的结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RequestInterceptor current thread name: XNIO-5 task-1 , id: 187</span><br><span class="line">MyFeignRequestInterceptor current thread name: hystrix-bling-share-xdfproducer-1 , id: 192</span><br></pre></td></tr></table></figure>
<p>可以明显的看到在<code>RequestInterceptor</code>拦截类中的线程和<code>MyFeignRequestInterceptor</code>拦截类中的线程并不是同一个线程，也没有父子关系，所以在Feign的拦截类是无法获取到traceId。</p>
<p><strong>所以现在的问题是如何解决不同线程之间数据共享的问题</strong>？</p>
<hr>
<p>分析：虽然当前请求的两个拦截类<strong>不处于同一个线程内，但却是处于同一个请求的生命周期内，那我们只要找到一种方法把变量设置到一个<code>request scope</code>的共享变量</strong>，那么这个请求周期内无论有多少个线程，我们设置的信息就都可以随时被这次请求内的线程获取到，也就间接地实现了线程间的信息共享。</p>
<h3 id="HystrixRequestVariableDefault"><a href="#HystrixRequestVariableDefault" class="headerlink" title="HystrixRequestVariableDefault"></a>HystrixRequestVariableDefault</h3><p>“Default implementation of  HystrixRequestVariable. Similar to ThreadLocal but scoped at the user request level. Context is managed via HystrixRequestContext”</p>
<p><code>HystrixRequestVariableDefault</code>类是Hystrix Concurrency包提供的一个类，类似于<code>ThreadLocal</code>，<strong>但是它的生命周期是用户请求级别的</strong>，所以我们来尝试用它来解决同义词请求线程间数据共享的问题。</p>
<p>在使用HystrixRequestVariableDefault类的时候要注意，因为这是一个整个请求范围内的，我们需要将其定义为一个全局的变量，同时要注意<code>Context is managed via HystrixRequestContext</code>这句话，我们在使用之前需要使用HystrixRequestContext.initializeContext()来初始化，否则将会抛出NPE。</p>
<p>我们首先定义一个全局的<code>HystrixRequestVariableDefault&lt;String&gt;</code>对象。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HystrixCredentialsContext</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> HystrixRequestVariableDefault&lt;String&gt; HYSTRIX_REQUEST_VARIABLE_DEFAULT =</span><br><span class="line">            <span class="keyword">new</span> HystrixRequestVariableDefault&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> HystrixRequestVariableDefault&lt;String&gt; <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> HYSTRIX_REQUEST_VARIABLE_DEFAULT;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义完全局变量之后，我们使用过滤器来实现请求的过滤，设置traceId。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HystrixRequestContextEnablerFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Logger log = LoggerFactory.getLogger(HystrixRequestContextEnablerFilter.class);</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain chain)</span> <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        HystrixRequestContext context = HystrixRequestContext.initializeContext();</span><br><span class="line">        HttpServletRequest httpRequest = (HttpServletRequest) request;</span><br><span class="line">        String traceId = httpRequest.getHeader(LOG_TRACE_ID);</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isBlank(traceId))&#123;</span><br><span class="line">            traceId = UuidUtil.get32UUID();</span><br><span class="line">        &#125;</span><br><span class="line">          MDC.put(LOG_TRACE_ID, traceId);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            HystrixCredentialsContext.getInstance().set(traceId);</span><br><span class="line">            log.info(<span class="string">"Set traceId successful: &#123;&#125;"</span>, traceId);</span><br><span class="line">            chain.doFilter(request, response);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            MDC.clear();</span><br><span class="line">            context.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException </span>&#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>好了，经过这一番改造，我们再来尝试在<code>MyFeignRequestInterceptor</code>类中获取log_trace_id.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFeignRequestInterceptor</span> <span class="keyword">implements</span> <span class="title">RequestInterceptor</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Logger log = LoggerFactory.getLogger(MyFeignRequestInterceptor.class);</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(RequestTemplate template)</span> </span>&#123;</span><br><span class="line">           <span class="comment">// 这里不再使用MDC来获取了</span></span><br><span class="line">            String traceId = HystrixCredentialsContext.getInstance().get();</span><br><span class="line">            log.info(<span class="string">"print current thread logTraceId: &#123;&#125;"</span>, traceId);    </span><br><span class="line">           <span class="keyword">if</span> (StringUtils.isNotBlank(traceId))&#123;</span><br><span class="line">            template.header(LOG_TRACE_ID, traceId);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过日志，我们能看到这次确实能够拿到<code>traceId</code>了，说明我们采用<code>HystrixRequestVariableDefault</code>来解决线程间的数据共享是成功的。</p>
<h5 id="但是现在还有一个问题没解决：为什么有的服务不采用HystrixRequestVariableDefault来实现数据共享也能拿到traceId呢？"><a href="#但是现在还有一个问题没解决：为什么有的服务不采用HystrixRequestVariableDefault来实现数据共享也能拿到traceId呢？" class="headerlink" title="但是现在还有一个问题没解决：为什么有的服务不采用HystrixRequestVariableDefault来实现数据共享也能拿到traceId呢？"></a>但是现在还有一个问题没解决：<strong>为什么有的服务不采用<code>HystrixRequestVariableDefault</code>来实现数据共享也能拿到traceId呢</strong>？</h5><p>为了表述的方便，这里使用A来代表<strong>不采用</strong><code>HystrixRequestVariableDefault</code>也能获取到MDC的traceID的微服务，B来代表<strong>采用</strong>这种方式的微服务。</p>
<p>为了定位问题，我们分别在两个微服务的请求过滤器和Feign调用拦截器中打印当前线程的<strong>线程组名称、线程名、线程ID</strong>信息来帮助定位问题，下面是日志打印:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A服务：</span><br><span class="line"> main, thread name: XNIO-5 task-1, thread id: 185</span><br><span class="line"> main, thread name: XNIO-5 task-1, thread id: 185</span><br><span class="line"></span><br><span class="line">B服务：</span><br><span class="line">main, thread name: XNIO-5 task-1, thread id: 177</span><br><span class="line">main, thread name: hystrix-B-1, thread id: 182</span><br></pre></td></tr></table></figure>
<p>从上边我们可以看出，A服务在过滤器和拦截器中均为同一个线程，所以才能通过MDC获取到traceId，而B服务并非同一个线程，自然无法通过MDC拿到。</p>
<p><strong>那么现在问题来了，为什么A服务使用同一个线程，则B服务却是不同的线程</strong>？？</p>
<p>通过对比A和B的配置，发现在B的服务中配置了<code>feign.hystrix.enabled=true</code>，而A服务却没有配置，经过验证之后确认是因为此配置导致A和B在调用微服务时，<strong>采用了不同的线程策略</strong>。</p>
<h3 id="Hystrix-feign请求流程"><a href="#Hystrix-feign请求流程" class="headerlink" title="Hystrix feign请求流程"></a>Hystrix feign请求流程</h3><p>在上边B服务配置了<code>feign.hystrix.enabled=true</code>参数，也就是说B服务的Feign调用开启了熔断的的功能，因为开启了熔断，所以发起远程调用的时候Hystrix重启根据当前所调用的微服务使用了一个新的线程去处理远程调用，下边是Feign发起远程调用的完整流程。</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1595245562/feign2_upi4wh.png" width="70%" height="70%"></p>
<p>从上图可以看到，第1步就是通过JDK动态生成代理类代理类，比较重要的是下边这段代码。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(<span class="keyword">final</span> Object proxy, <span class="keyword">final</span> Method method, <span class="keyword">final</span> Object[] args)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">      .....</span><br><span class="line">    HystrixCommand&lt;Object&gt; hystrixCommand = <span class="keyword">new</span> HystrixCommand&lt;Object&gt;(setterMethodMap.get(method)) &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">protected</span> Object <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> HystrixInvocationHandler.<span class="keyword">this</span>.dispatch.get(method).invoke(args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">          <span class="keyword">throw</span> (Error) t;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    .......</span><br></pre></td></tr></table></figure>
<p>其中最重要的一行代码就是<code>HystrixInvocationHandler.this.dispatch.get(method).invoke(args);</code>它将会生成一个新的<code>hystrixCommand</code>，同时启动一个新的线程。具体细节可以参考这里<a href="https://www.programmersought.com/article/68091584946/" target="_blank" rel="noopener">Hystrix feign thread model</a>。因为第一步就创建了新的线程，所以在上图中第五步拦截的时候使用的就是这个新创建的线程。</p>
<p>到这里为止，我们也就能解释为什么A服务使用了同一个线程，则B服务却是不同的线程。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://www.programmersought.com/article/68091584946/" target="_blank" rel="noopener">Hystrix feign thread model</a></li>
<li><a href="https://juejin.im/post/5e79bce5e51d4527235b8878" target="_blank" rel="noopener">SpringBoot+MDC实现全链路调用日志跟踪</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1484945" target="_blank" rel="noopener">在Java项目中使用traceId跟踪请求全流程日志</a></li>
<li><a href="https://programming.vip/docs/spring-cloud-openfeign-source-code-analysis.html" target="_blank" rel="noopener">Spring Cloud OpenFeign source code analysis</a></li>
<li><a href="https://juejin.im/post/5df19a4751882512816014e2" target="_blank" rel="noopener">Feign源码分析:记初次使用Feign踩的一些坑</a></li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2020/07/14/记一次实现日志完整链路追踪（log_trace_id）踩到的坑/" data-id="ckczxj13l0002buyn0snd2rdd" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-浅谈计算机领域的缓存" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2020/07/07/浅谈计算机领域的缓存/">浅谈计算机领域的缓存</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2020/07/07/浅谈计算机领域的缓存/" class="article-date">
  <time datetime="2020-07-07T07:06:17.000Z" itemprop="datePublished">2020-07-07</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/计算机基础/">计算机基础</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h1 id="浅谈计算机领域的缓存"><a href="#浅谈计算机领域的缓存" class="headerlink" title="浅谈计算机领域的缓存"></a><center>浅谈计算机领域的缓存</center></h1><p><img src="https://res.cloudinary.com/leon824/image/upload/v1594113581/it_photo_113632_qkdoaw.jpg" alt></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>缓存可以说在计算机领域无处不见，底层硬件的<strong>Cpu高速缓存</strong>、<strong>磁盘缓存</strong>；处于网路边缘的<strong>Dns缓存</strong>、<strong>Web缓存</strong>、<strong>Http缓存</strong>、<strong>DNS</strong>；应用服务中的<strong>数据库缓存</strong>、<strong>分布式缓存</strong>、<strong>本地缓存</strong>等等。这些缓存都有哪些特点？为什么缓存被大量使用？有哪些优缺点？今天我们从横向分类归纳的方式来探讨一下这个问题。</p>
<h2 id="一、为什么需要缓存？"><a href="#一、为什么需要缓存？" class="headerlink" title="一、为什么需要缓存？"></a>一、为什么需要缓存？</h2><p>在探讨为什么需要缓存之前，我们先来看看具体的几个例子，看看缓存在实际场景中给我们解决了哪些问题。</p>
<h4 id="1、CPU高速缓存"><a href="#1、CPU高速缓存" class="headerlink" title="1、CPU高速缓存"></a>1、CPU高速缓存</h4><p>首先我们来看第一种情况，众所周知，CPU可以直接访问的存储设备只有<strong>内存</strong>和<strong>内置的寄存器</strong>，如果数据没有处于这些存储设备中，那么需要先加载到内存中，CPU才能直接访问。<br>CPU访问内置寄存器通常在一个时钟周期便可完成。而对于内存来说就不行了，完成一次内存访问通常需要多个时钟周期才能完成，那么由于没有数据以便完成正在执行的指令，CPU通常需要<strong>暂停（stall）</strong>，而且由于内存访问非常频繁（相对寄存器，内存的容量大得多），所有这种情况是无法容忍的。</p>
<p>解决上边CPU频繁暂停的办法是什么呢？ 答案就是通过增加<strong>高速缓存</strong>（CPU访问速度比内存快很多）来<strong>调和CPU访问内存过慢的问题</strong>。具体原理可以参考coolshell的<a href="https://coolshell.cn/articles/20793.html" target="_blank" rel="noopener">这篇文章</a></p>
<p>与此类似的场景还有<strong>磁盘缓存</strong>，同样是为了调和内存与磁盘之间速度的差异。</p>
<h4 id="2、Web缓存"><a href="#2、Web缓存" class="headerlink" title="2、Web缓存"></a>2、Web缓存</h4><p>假设小明使用浏览器正在请求下载一个最新的Ubuntu ISO，链接为<code>https://releases.ubuntu.com/20.04/ubuntu-20.04-desktop-amd64.iso</code>，若资源的服务器地址在美国，那么由于链路过长，而<strong>下载的速度由整个链路的瓶颈决定的</strong>，所以整个下载速度将受到很多因素影响；于此同时，和你处于同一个局域网的另外一个人，也想下载同一个资源，那么他也不得不重新发起一个下载请求，忍受很慢的下载速度，且互联网的带宽是有上限的，<strong>大量重复的数据传输将大大增加链路的拥塞，从而导致整体下行速度更慢</strong>。</p>
<p>要解决这个问题的办法就是在用户和目标资源服务器之间增减<strong>WEB缓存</strong>，资源首次访问之后，将会缓存到<strong>Web缓存器</strong>（拥有自己的磁盘存储空间）中，<strong>在一段时间内</strong>相同区域内的用户也需要下载同样的资源的话，那么就可以直接在Web缓存中获取到资源，而不需要去访问远端的资源。<strong>从而减少因特网中的通信量，并且大大减少用户的请求时间</strong>。如下图：<br><img src="https://res.cloudinary.com/leon824/image/upload/v1593178231/catch-1_bzmvew.png" alt></p>
<h2 id="二、缓存的分类"><a href="#二、缓存的分类" class="headerlink" title="二、缓存的分类"></a>二、缓存的分类</h2><p>上边的对于<strong>CPU高速缓存</strong>和<strong>Web缓存</strong>的两种场景下缓存的使用，我将缓存分为两种类型。</p>
<h3 id="1、调和速度差异型"><a href="#1、调和速度差异型" class="headerlink" title="1、调和速度差异型"></a>1、调和速度差异型</h3><p>见名知意，这类缓存主要的主要作用就是<strong>调和两种资源之间速度的差异</strong>，从而减少高速设备的等待时间，最终实现整体性能的提升。例如<strong>Cpu高速缓存</strong>、<strong>磁盘缓存</strong>、<strong>分布式缓存</strong>等等，都是此类目的。关于Cpu高速缓存的具体原理介绍，可以参考维基<a href="https://zh.wikipedia.org/wiki/CPU%E7%BC%93%E5%AD%98#:~:text=%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B8%AD%EF%BC%8CCPU,%E5%86%85%E6%98%AF%E5%90%A6%E6%9C%89%E8%AF%B7%E6%B1%82%E6%95%B0%E6%8D%AE%E3%80%82" target="_blank" rel="noopener">这篇文章</a></p>
<h3 id="2、降低成本型"><a href="#2、降低成本型" class="headerlink" title="2、降低成本型"></a>2、降低成本型</h3><p>a、此类型可能更多的用于<strong>“网络边缘”设备</strong>，例如上边介绍的Web缓存。主要目的就是为了降低<strong>使用成本</strong>，当我们请求一个资源之后将缓存到距离我们更近的web缓存服务器中，当我们下次访问则可以直接命中局域网内已经缓存的资源，达到直接降低使用成本的目的。</p>
<p>b、还有例如我们使用Mysql数据库时，当我们执行一个Sql查询语句，数据库并不会立即去解析语法树、执行sql这些动作，<strong>而是先将计算此Sql的Hash值，然后通过这个Hash值去缓存中查询是否已经缓存，若命中直接返回之前已经缓存的结果给用户</strong>，这就能极大地降低查询成本。</p>
<p>c、我们在程序中通常会将计算/获取成本较高的数据缓存起来，以备下一次使用时直接在内存中访问，降低响应时间、提高服务的吞吐量。</p>
<hr>
<p>使用缓存的场景非常非常多，但大体离不开这两种类型。有时候缓存<strong>兼具以上两种类型的特征</strong>，例如使用Redis做分布式缓存，既可以为调和数据库资源、访问速度有限的问题；同时也可将应用中需要频繁使用且计算成本高的数据缓存起来，实现降低使用成本的目的。</p>
<h2 id="三、使用缓存需要注意的问题"><a href="#三、使用缓存需要注意的问题" class="headerlink" title="三、使用缓存需要注意的问题"></a>三、使用缓存需要注意的问题</h2><p>通过上边的介绍，我们知道缓存给我们带来系统性能上的极大提升，但是使用缓存也需要注意下边的两个问题，否则“理想是美好的，现实是骨感的”。</p>
<h3 id="1、如何解决数据一致性的问题？"><a href="#1、如何解决数据一致性的问题？" class="headerlink" title="1、如何解决数据一致性的问题？"></a>1、如何解决数据一致性的问题？</h3><p>首先在这里我们以<strong>”微观“</strong>的角度来分析<strong>多核CPU缓存一致性</strong>和来探讨。</p>
<h4 id="多核CPU缓存一致性问题"><a href="#多核CPU缓存一致性问题" class="headerlink" title="多核CPU缓存一致性问题"></a>多核CPU缓存一致性问题</h4><p>我们首先来看一下为什么会产生缓存一致性的问题，假设<code>cpu、cache、main memory</code>的架构如下图所示：</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1594101087/cpu-3_vbqxpx.png" alt></p>
<p>两个cpu共享同一个缓存，这样当缓存中的数据更新之后，<strong>cpu-0、cpu-1读取到的数据自然是相同的，此时不存在缓存一致性问题</strong>，但是由于此时缓存属于<strong>“临界区资源”</strong>，为了避免多核CPU同时读写而产生的<strong>临界区资源安全</strong>的问题，那么就需要加锁，那此时也就极大地降低了系统的运算速度，因为很多CPU都在排队等待缓存可用。所以现代CPU的架构都是每一个CPU都有属于自己的缓存，也就是说缓存一致性是多缓存引起的，而不是多CPU带来的。</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1594028869/cache-1_sx4psn.png" alt></p>
<p>在上图中，假设一个消息m，更新到<code>cache-0</code>中，那么这个时候也需要立即将m更新到<code>cache-1</code>中，这就属于CPU缓存一致性问题了。</p>
<p>一般来说，在CPU硬件上，会有两种方法来解决这个问题。</p>
<ul>
<li><p>Directory 协议：这种方法的典型实现是要设计一个<strong>集中式控制器</strong>，它是主存储器控制器的一部分。其中有一个目录存储在主存储器中，其中包含有关各种本地缓存内容的全局状态信息。当单个CPU Cache发出读写请求时，这个集中式控制器会检查并发出必要的命令，以在主存和CPU Cache之间或在CPU Cache自身之间进行数据同步和传输。</p>
</li>
<li><p>Snoopy 协议。这种协议更像是一种<strong>数据通知的总线型</strong>的技术。<code>CPU Cache</code>通过这个协议可以识别其它Cache上的数据状态。如果有数据共享的话，可以通过广播机制将共享数据的状态通知给其它<code>CPU Cache</code>。这个协议要求每个<code>CPU Cache</code>都可以“窥探”数据事件的通知并做出相应的反应。</p>
</li>
</ul>
<p>从上边两种协议的描述我们就可以看出，Directory协议是中心式的，会有性能瓶颈，而且会增加整体设计的复杂度。而Snoopy协议更像是<strong>微服务+消息通讯</strong>，所以，现在基本都是使用Snoopy的总线的设计。在分布式系统中我们一般用Paxos/Raft这样的分布式一致性的算法。而在CPU的微观世界里，则不必使用这样的算法，原因是因为<strong>CPU的多个核的硬件不必考虑网络会断会延迟的问题</strong>。所以，CPU的多核心缓存间的同步的核心就是要管理好<strong>数据的状态</strong>就好了。</p>
<p>对于数据状态管理的协议主要有：MESI协议、MOESI协议等等，具体可以参考维基百科的两篇文章：<a href="https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">MESI协议</a>、<a href="https://en.wikipedia.org/wiki/MOESI_protocol" target="_blank" rel="noopener">MOESI protocol</a></p>
<h3 id="2、如何提高命中率？"><a href="#2、如何提高命中率？" class="headerlink" title="2、如何提高命中率？"></a>2、如何提高命中率？</h3><p>在使用缓存的场景中，在如何提高命中率这一点，我们需要特别的重视，较高的缓存命中率可以大幅的提高我们系统的吞吐量，降低响应时间。这里我们从<strong>宏观</strong>角度来分析，这里以Redis为例。</p>
<p>我们先来看一下影响缓存命中率的几个关键点：</p>
<ul>
<li><p>1、业务场景：我们在缓存数据之前要确认，当前的数据是否为<strong>“读多写少” </strong>？若相反，则没有必要使用缓存来增加系统的复杂度，直接查库即可。</p>
</li>
<li><p>2、数据粒度：通常来说，我们缓存数据的<strong>粒度</strong>相对小的时候，被命中的概率会比较高。举个例子，假设我们缓存班级里某一个学生的信息和缓存整个班级的信息相比，这个学生的信息在同样的时间范围内被修改的概率肯定是要小于班级里任意一个人被修改的概率，而数据数据一旦被修改，此时缓存失效，需要重新从DB中加载数据块，缓存也随之失效。</p>
</li>
<li><p>3、缓存容量和基础设施：Redis缓存之所以能够相比DB块，是因为缓存中的数据在内存中，但是我们知道内存容量相对磁盘是很有限的，所以缓存不可能一直在内存中驻留，那么就需要定义<strong>超时时间</strong>和缓存数据淘汰算法（目前大多数都采用LRU来作为淘汰算法）。为数据项定义合理的失效时间和淘汰算法对提高命中率也是非常重要的。</p>
</li>
</ul>
<p>同时，缓存的技术选型也是至关重要的，比如采用应用内置的本地缓存就比较容易出现单机瓶颈，而采用分布式缓存则毕竟容易扩展。所以需要做好系统容量规划，并考虑是否可扩展。此外，不同的缓存框架或中间件，其效率和稳定性也是存在差异的。</p>
<p>要提高缓存的命中率，我们就需要在业务场景、粒度和策略、缓存容量和基础设施选型这几个方面去全面分析、妥协，达到一个综合效果最好的目的。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><p>《操作系统概念》</p>
</li>
<li><p>《计算机网络——自顶向下方法》</p>
</li>
<li><p><a href="https://zh.wikipedia.org/wiki/%E7%BC%93%E5%AD%98" target="_blank" rel="noopener">缓存</a></p>
</li>
<li><p><a href="https://tech.meituan.com/2017/03/17/cache-about.html" target="_blank" rel="noopener">缓存那些事</a></p>
</li>
<li><p><a href="https://developer.aliyun.com/article/248256" target="_blank" rel="noopener">如何提高缓存命中率</a></p>
</li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2020/07/07/浅谈计算机领域的缓存/" data-id="ckcbq40py000010ynho3ttvjk" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-历史的逻辑" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2019/02/18/历史的逻辑/">历史的逻辑</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2019/02/18/历史的逻辑/" class="article-date">
  <time datetime="2019-02-18T08:32:34.000Z" itemprop="datePublished">2019-02-18</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/读书笔记/">读书笔记</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h2 id="历史的逻辑"><a href="#历史的逻辑" class="headerlink" title=" 历史的逻辑"></a><center> 历史的逻辑</center></h2><h4 id="–-读《晚清到民国》有感"><a href="#–-读《晚清到民国》有感" class="headerlink" title="– 读《晚清到民国》有感"></a><p align="right">– 读《晚清到民国》有感</p></h4><p>&emsp;&emsp;给自己定下了一个目标——每读完一本书就要写一点读书感想，希望从今天开始坚持下来。<br>    余讀此書，給我最大的感受便是，孫文所講的：“天下大勢，順之則昌，逆之則亡”。從1840年起，距今快180年，這個過程仍然沒有結束。下邊就嘗試自己來總結一下整個過程。<br>&emsp;&emsp;沉睡中的帝國第一次被敲醒，西方文明從文藝復興啟動“中古文化”的現代化過程，經歷大航海時代、工業革命。已經在政治體制、工業生產力、科學文化創新等方方面面超過東方的古老文明。從一個小例子便能看出來。乾隆年間，英國公使代表英王送來當時西方最先進的步槍、以及其他代表当时最先进科技的“贡品”。而乾隆皇帝則表示：我大天朝富有四海，豈需要而小國貨物哉？特別是當庚子國變之後，八國聯軍進入北京，發現當初马戛尔尼使团当初送给乾隆皇帝的步枪放在仓库中甚至都没有打开过，高傲無知可見一斑。<br>&emsp;&emsp;至于第一次鸦片战争，站在今天人的角度看，其结果不言自明，以一个落后的非现代化国家和一个强大的英帝国作战，失败是毫无疑问的。但是当时的人并没有机会开启“上帝之眼”。在当时道光皇帝看來，我天朝擁有四萬萬國民，焉能輸給遠在萬裡之遙的撮兒小國？兒只有林文忠公——中國近代開眼看世界的第一人，在戰爭開始之後，林則徐則知道這是一場不對稱的戰爭，失敗是沒有疑問的，然而皇帝堅持要打，也是毫無辦法的事情。至於兒戰後所簽署的中國近代第一個“不平等”條約——《南京條約》，從今人的角度看來并非為不平等條約，比如開放五口通商，有一點經濟學知識的人都能夠知道，當市場覆蓋越大，邊越能夠促進生產力的發展，對資源的充分利用同樣大有裨益。然而站在當時的統治者角度，我并不願意和你們通商，你強迫我，那就是不平等。 最終，不管你願意不願意，們是被一幫外來者砸出了一個大口子，再也不能獨善其身了。<br>&emsp;&emsp;在第二次鴉片戰爭之前，還發生了讓中國人口減少上億人口的太平天國運動，在王朝統治的末年，統治機器已經腐朽不堪，對底層老百姓無法實現有效統治，甚至有災不賑，那麼底層老百姓也就只能造反了。作者在書中詳細介紹了洪秀全本人的生平，和歷史上很多農民起義類似，底層農民起義無非就是為了金子、女人而已，一旦獲得了不受限制的權利，那麼老百姓就要遭殃了 ！！！<br>&emsp;&emsp;隨之而來的就是第二次鴉片戰爭，這次英法聯軍攻破首都——北京，這也是近代第一次天朝第一次首都被攻陷，咸豐皇帝跑到承德避暑山莊，英法聯軍火燒圓明園，此乃是帝國中醫侵略中國的最重要罪證之一，今日每個中國人提到此事仍然要咬牙切齒的罵上兩句。但是要知道，在這次戰爭之前，慈禧太后將38名外國使臣殺頭、囚禁在圓明園內，致使最後僅僅十幾位還活著，加上第一次鴉片戰爭所簽署的《南京條約》中方一致推諉，不允許外國人“入境”。多個原因之下，發生了第二次鴉片戰爭。歸根到底，還是這個龐大的帝國沒有切換思路，然後是保留著受害者心態、中學為體西學為用的保守思想，要知道早在大航海時代就已經進行的全球融合豈是你大清國能夠阻擋的？也許在當時的統治者來說，我們並沒有錯啊。是的，這就是天下大勢，不會以個人、國家而改變。<br>&emsp;&emsp;要說清代末年最重要的戰爭，除了第一次鴉片戰爭，可能就是甲午中日戰爭了。這次和我們東邊的老鄰居、“撮兒小國”—— 日本的戰爭。幾乎是導致大清帝國解體最重要的一擊了。本來已經在第二次鴉片戰爭之後的三十年有中興之象，然而一戰戳破所有幻想。世界第八的海軍輸給世界十四的日本，所有的民族自尊心被擊碎、直至今日仍是如此。書中讀到這段歷史的時候感慨頗多，一個國家的“國運”往上走的時候，真實一順百順；若是“國運”往下走的時候，便不是人力所能改變的了。想想當初日本人立志想要打造海軍，上萬日本婦女們為了國家下南洋賣淫來籌集軍費，而我們的老佛爺還要挪用上千萬的軍費來建造自己退休的園子——頤和園。也許看到這裡，也就不需要在去關注戰爭本身的細節了，勝負其實早在戰爭之前就已經註定了，無需多言。<br>&emsp;&emsp;時針撥到1900年，也就是庚子年。這一次八國聯軍侵華又是由於義和團對洋人的攻擊而直接導致。吊詭的是，義和團產生的一個重要原因便是洋人在中國的作威作福，和底層老百姓發生沖突的時候地方官府根本對洋人無可奈何，吃虧的只能是中國的老百姓。君不知，當時一個主教和一方大員的巡撫、總督處於同一級別！ 於是一幫叫義和拳的群體漸漸成長起來，他們的口號是“扶清滅洋”。當時的慈禧老太太當然也知道這幫人不過是虛張聲勢的一幫烏合之眾，但是“其心可用”。 但是真正讓慈禧下決心向十一國宣戰的真正原因乃是“蔣幹偷書”，其中最重要的一條是讓慈禧還政于光緒皇帝。君不見，獨裁者最怕的永遠都是失去權利，而國家的興亡、普通老百姓的死活不在她的考慮範圍內，如此史上“最勇敢”的老太太便誕生了，以已過之力，向所有邦交國宣戰，要知道拿破崙、希特勒、斯大林都沒這樣“勇敢”過。結果也是不出意料，幾萬雜牌聯軍在很短的時間內邊攻破北京，帝國的首都便再一次被蹂躪，遭殃的當然還是帝都的老百姓。<br>&emsp;&emsp;至於後邊的辛亥革命則是壓死駱駝的最後一根稻草，意味著2000多年的帝國統治的結束。然後從1912年到今天，整整100多年過去了，我們的“中古文化現代化”就完成了嗎？在唐先生的觀點開來，大概要等到2040年，具體第一次鴉片戰爭200年方能完成。這個觀點在我有限的認知裡邊是讚成的，今日之中國看似包著一個現代化國家的外衣，骨子里還是帝王的那一套。正好此時此刻正在南美洲-阿根廷召開的G20峰會正在舉行，最重要的中美元首會面也將在十幾個小時之後進行，這次會面也許是一個轉折點，決定中美是否能否緩和關係，還是繼續升級對抗，邊拭目以待吧。<br>&emsp;&emsp;歷史很多時候就是“不識廬山真面目，只緣身在此山中”，今日所發生的很多事情，我們沒有辦法去證實、弄明白背後真正的緣由，好在歷史有其自身的邏輯，今日之事會在未來有一個清楚的交代。<br>                   </p><p align="right">2018/12/1</p>  <p></p>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2019/02/18/历史的逻辑/" data-id="ckbyfke0k0009zbyn5dziktym" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-单例模式的线程安全问题" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2018/09/07/单例模式的线程安全问题/">单例模式的线程安全问题</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/09/07/单例模式的线程安全问题/" class="article-date">
  <time datetime="2018-09-07T07:28:47.000Z" itemprop="datePublished">2018-09-07</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1536228571/arches-national-park-dark-dusk-33688_onguan.jpg" width="100%" height="100%"></p>
<h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><p>单例模式是最简单的设计模式，分为两种：懒汉模式、恶汉模式</p>
<h3 id="恶汉模式"><a href="#恶汉模式" class="headerlink" title="恶汉模式"></a>恶汉模式</h3><p>在属性中直接创建对象，然后在方法中返回。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singletom</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singletom ourInstance = <span class="keyword">new</span> Singletom();</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singletom <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ourInstance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singletom</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面不存在线程安全的问题，因为加载类的时候就会创建<code>Singletom</code>的对象，然后所有线程来获取的时候都是返回这个对象。</p>
<h3 id="懒汉模式"><a href="#懒汉模式" class="headerlink" title="懒汉模式"></a>懒汉模式</h3><p>刚开始并不直接创建对象，而是在需要的时候在创建，主要代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OtherSingleton</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> OtherSingleton instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">OtherSingleton</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> OtherSingleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">             <span class="keyword">if</span> (instance == <span class="keyword">null</span>)&#123;      ————<span class="number">1</span></span><br><span class="line">                 instance = <span class="keyword">new</span> OtherSingleton(); —————<span class="number">2</span></span><br><span class="line">                 <span class="keyword">return</span> instance;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个时候是线程不安全的，假设两个线程一前一后来执行<code>getInstance()</code>方法，这个时候线程<strong>A</strong>正在执行2这个位置，由于<code>new</code>对象并非一个<strong>原子操作</strong>，分为以下<strong>三步</strong>：</p>
<ul>
<li>1) 在内存中分配空间。</li>
<li>2) 调用构造函数初始化对象。</li>
<li>3）将<code>instance</code>引用指向堆内存空间的起始地址（此时<code>instance</code>才为非<code>null</code>）。</li>
</ul>
<p>若将上边三步用伪代码来表示就是下边这样：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">memory = allocate();  <span class="comment">//  1、分配对象的内存空间</span></span><br><span class="line">ctorInstance(memory); <span class="comment">// 2、初始化对象</span></span><br><span class="line">instance = memory；  <span class="comment">//3、设置instance指向刚分配的内存地址</span></span><br></pre></td></tr></table></figure>
<p>实际上在上边的伪代码中2和3之间，可能会被重排序（在一些JIT编译器上，这种重排序也是真实发生的） ，根据《java语言规范》，所有线程在执行java程序时必须遵守<strong>intra-thread semantics</strong>,<strong>intra-thread semantics</strong>保证排序不会改变单线程的执行结果。换句话说，<strong>intra-thread semantics</strong>允许那些在单线程中不改变执行结果的重排序，这样会提高程序的执行性能。</p>
<p>这个时候<strong>A</strong>线程执行刚刚才执行到创建对象的<strong>第二步</strong>，线程<strong>B</strong>就执行到代码<strong>1</strong>处，此时判断出<code>instance</code>为<code>null</code>，然后进入对象在创建一个对象！ 这个时候就出现问题了，单例模式此时创建了两个对象。违背了单例模式的初衷。</p>
<h3 id="双重锁检查"><a href="#双重锁检查" class="headerlink" title="双重锁检查"></a>双重锁检查</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OtherSingleton</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> OtherSingleton instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">OtherSingleton</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> OtherSingleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>)&#123;  ————<span class="number">1</span></span><br><span class="line">            <span class="keyword">synchronized</span> (OtherSingleton.class)&#123;</span><br><span class="line">             <span class="keyword">if</span> (instance == <span class="keyword">null</span>)&#123;    ————<span class="number">2</span></span><br><span class="line">                 instance = <span class="keyword">new</span> OtherSingleton();   ————<span class="number">3</span></span><br><span class="line">                 <span class="keyword">return</span> instance;</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里加双重检查锁就是在同步代码前和同步代码后边都检查实例是否为空。如果仅仅在同步块外边检查，而在同步块内不检查，那么可能存在多个线程同时进入了同步块外的代码，则可能<strong>生成多个实例</strong>。</p>
<p>上边代码看起来还不错，但是他还是有问题的。问题出现在代码<strong>3</strong>处，这个地方并非是原子操作，如上边的描述分为<strong>三步</strong>。由于<code>cpu</code>为了提高执行效率可能会将这个三步分为<strong>1-2-3</strong>或者<strong>1-3-2</strong>。</p>
<p>如果线程<strong>A</strong>执行到代码<strong>3</strong>处的<strong>1-3</strong>步，此时<code>instance</code>已经不为<code>null</code>了，但是创建对象的第二部却并没有执行。而此时线程<strong>B</strong>进入到方法的<strong>1</strong>处，判断<code>instance</code>是否为空，此时已经不会空了，但是返回的对象却并没有初始化，顺理成章的报错。。</p>
<p>这里的关键是<code>instance</code>对象还没有初始化执行<strong>第二步</strong>，就执行的<strong>第三步</strong>，导致线程<strong>B</strong>拿到一个空的对象。那么我们只需要让<code>cpu</code>在执行创建对象时禁止重排序就能够解决这个问题了。<br>明显需要使用<code>volatile</code>关键字来禁止重排序。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OtherSingleton</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> OtherSingleton instance;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">OtherSingleton</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> OtherSingleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (OtherSingleton.class)&#123;</span><br><span class="line">             <span class="keyword">if</span> (instance == <span class="keyword">null</span>)&#123;</span><br><span class="line">                 instance = <span class="keyword">new</span> OtherSingleton();</span><br><span class="line">                 <span class="keyword">return</span> instance;</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里利用的是<code>volatile</code>的禁止重排序的性质，在<code>volatile</code>变量的赋值操作后边会加上一个内存屏障，<strong>读操作</strong>不会出现在内存屏障前边，所以<strong>取操作*必须是</strong>1-2-3<strong>或者</strong>1-3-2<strong>之后，不存在</strong>1-3**之后就读取到。从<code>happen-before</code>原则来看，就是对于一个 <code>volatile</code> 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/" target="_blank" rel="noopener">如何正确地写出单例模式</a></li>
<li>《java并发编程的艺术》</li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2018/09/07/单例模式的线程安全问题/" data-id="ckbyfke0i0008zbyn8x6kpl5g" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-分布式调度中心" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2018/09/06/分布式调度中心/">分布式调度中心</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/09/06/分布式调度中心/" class="article-date">
  <time datetime="2018-09-06T09:22:37.000Z" itemprop="datePublished">2018-09-06</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <p><img src="https://res.cloudinary.com/leon824/image/upload/v1536228539/america-american-american-flag-92730_nxhmbn.jpg" width="90%" height="90%"></p>
<blockquote>
<p>最近公司的服务已经从传统tomcat服务拆分成了微服务，使得各个原本臃肿的业务变得轻量、易维护，但是也带了一些问题，比如生产、测试环境中的定时任务管理就成了问题，由于服务器变得更多，定时任务变得分散，各个环境容易变得混杂、维护成本升高且容易出错，同时无法知道这个定时任务执行是否成功，只有当服务出现了问题才能反推定时任务出现了问题。</p>
</blockquote>
<h2 id="使用系统级定时crontab存在的主要问题"><a href="#使用系统级定时crontab存在的主要问题" class="headerlink" title="使用系统级定时crontab存在的主要问题"></a>使用系统级定时crontab存在的主要问题</h2><ul>
<li>任务的时间粒度不够小（只能是分钟级别以上）</li>
<li>当任务没有执行的时候没有通知，不能及时发现定时任务是否执行，只有当出现异常的时候才能发现定时的执行出现了问题。</li>
<li>任务执行过程没有日志记录，出现的问题不容易定位</li>
<li>没有失败处理策略（失败重试、失败告警）</li>
<li>没有阻塞策略</li>
<li><p>依赖运维人员，低效</p>
<p>那么上边这些问题要怎样解决呢？ 我们可以使用分布式调度系统来彻底解决这些痛点。</p>
</li>
</ul>
<h2 id="分布式调度系统"><a href="#分布式调度系统" class="headerlink" title="分布式调度系统"></a>分布式调度系统</h2><ul>
<li><code>TBSchedule</code>：阿里早期开源的分布式任务调度系统。代码略陈旧，使用timer而非线程池执行任务调度。众所周知，timer在处理异常状况时是有缺陷的。而且TBSchedule作业类型较为单一，只能是获取/处理数据一种模式。还有就是文档缺失比较严重</li>
<li><code>Saturn</code>：是唯品会自主研发的分布式的定时任务的调度平台，基于当当的elastic-job 版本1开发，并且可以很好的部署到docker容器上。</li>
<li><code>elastic-job</code>：当当开发的弹性分布式任务调度系统，功能丰富强大，采用zookeeper实现分布式协调，实现任务高可用以及分片，目前是版本2.15，并且可以支持云开发</li>
<li><code>xxl-job</code>: 是大众点评员工徐雪里于2015年发布的分布式任务调度平台，是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展</li>
</ul>
<p>在上边这几种解决方案中，以<strong>xxl-job</strong>和<strong>elastic-job</strong>用的更多、文档相对完善。</p>
<ul>
<li>共同点： <code>E-Job</code>和<code>X-job</code>都有广泛的用户基础和完整的技术文档，都能满足定时任务的基本功能需求。</li>
<li>不同点：<code>X-Job</code> 侧重的业务实现的简单和管理的方便，学习成本简单，失败策略和路由策略丰富。推荐使用在“用户基数相对少，服务器数量在一定范围内”的情景下使用<br><code>E-Job</code> 关注的是数据，增加了弹性扩容和数据分片的思路，以便于更大限度的利用分布式服务器的资源。但是学习成本相对高些，推荐在“数据量庞大，且部署服务器数量较多”时使用</li>
</ul>
<p>根据我们业务的数据量、用户数量可以采用<code>xxl-job</code>快速实现分布式任务调度中心。</p>
<h2 id="xxl-job下载、运行"><a href="#xxl-job下载、运行" class="headerlink" title="xxl-job下载、运行"></a>xxl-job下载、运行</h2><p>首先我们先去<code>github</code>中下载<code>xxl-job</code>最新的代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> git clone https://github.com/xuxueli/xxl-job.git</span><br></pre></td></tr></table></figure>
<p>  然后在<code>idea</code>中加载这个模块</p>
<p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1536229716/xxl-job2_dmcr7w.png" width="60%" height="60%"></p>
<p>  注意上边的三个黄色框圈起来的部分，从上往下：</p>
<p>  1、<code>tables_xxl_job.sql</code>这个是我们在库里边创建的库-表，执行之后会有16张表被创建</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> mysql -uroot -p &lt; tables_xxl_job.sql</span><br></pre></td></tr></table></figure>
<p>  <img src="  https://res.cloudinary.com/leon824/image/upload/v1536229989/xxl-job3_znsdti.png" width="40%" height="50%"></p>
<p>  2、<code>xxl-job-admin</code>就是调度中心，我们需要修改<code>resources</code>里边的<code>xxl-job-admin.properties</code>文件一些字段</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">### xxl-job db  (use &amp;amp; replace &amp; in xml)</span></span><br><span class="line"><span class="string">xxl.job.db.driverClass=com.mysql.jdbc.Driver</span></span><br><span class="line"><span class="string">xxl.job.db.url=jdbc:mysql://localhost:3306/xxl-job?useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line"><span class="string">xxl.job.db.user=root</span></span><br><span class="line"><span class="string">xxl.job.db.password=123456</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job email</span></span><br><span class="line"><span class="string">xxl.job.mail.host=smtp.163.com</span></span><br><span class="line"><span class="string">xxl.job.mail.port=25</span></span><br><span class="line"><span class="string">xxl.job.mail.username=ovono802302@163.com</span></span><br><span class="line"><span class="string">xxl.job.mail.password=asdfzxcv</span></span><br><span class="line"><span class="string">xxl.job.mail.sendNick=《任务调度平台XXL-JOB》</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job login</span></span><br><span class="line"><span class="string">xxl.job.login.username=admin</span></span><br><span class="line"><span class="string">xxl.job.login.password=123456</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job, access token</span></span><br><span class="line"><span class="string">xxl.job.accessToken=</span></span><br><span class="line"><span class="comment">### xxl-job, i18n (default empty as chinese, "en" as english)</span></span><br><span class="line"><span class="string">xxl.job.i18n=</span></span><br></pre></td></tr></table></figure>
<p>配置完成之后就可以启动了。</p>
<p> 3、 第三个是<code>xxl-job-executor-sample-springboot</code>这个是xxl-job提供的执行器中的一种，另外还支持<code>spring</code>等等，修改配置文件，将相应参数修改成和自己环境匹配的参数。</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># web port</span></span><br><span class="line"><span class="string">server.port=8081</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># log config</span></span><br><span class="line"><span class="string">logging.config=classpath:logback.xml</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"</span></span><br><span class="line"><span class="string">xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job executor address</span></span><br><span class="line"><span class="string">xxl.job.executor.appname=xxl-job-executor-sample</span></span><br><span class="line"><span class="string">xxl.job.executor.ip=</span></span><br><span class="line"><span class="string">xxl.job.executor.port=9999</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job, access token</span></span><br><span class="line"><span class="string">xxl.job.accessToken=</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### xxl-job log path</span></span><br><span class="line"><span class="string">xxl.job.executor.logpath=/Users/leon/work/logs/xxl-job/jobhandler</span></span><br><span class="line"><span class="comment">### xxl-job log retention days</span></span><br><span class="line"><span class="string">xxl.job.executor.logretentiondays=-1</span></span><br></pre></td></tr></table></figure>
<p> 上边执行器是具体执行任务的模块。下边就来具体讲讲xxl-job整体使用架构图。</p>
<p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1536054290/Pic2432_m0orgo.png" width="100%" height="90%"></p>
<p>  上图中虚线包围起来的两个部分就是xxl-job最重要的部分，一个叫<strong>调度中心</strong>，一个叫<strong>执行器</strong>（<em>我更愿意叫他<code>执行器群</code></em>）。其中<strong>调度中心</strong>负责所有执行器群的管理，各个执行器群的任务分发管理，日志的查询等等功能，而<strong>执行器</strong>负责具体执行任务。而中间的通讯组件则是自研的RPC组件，生产业务执行器就相当于是生产环境的执行器群，测试业务执行器相当于测试环境的执行器群。这样就能满足将各个环境通过执行器群来区分，然后统一管理起来在一个web后台就能处理所有环境的定时任务了。</p>
<h2 id="调度中心相关"><a href="#调度中心相关" class="headerlink" title="调度中心相关"></a>调度中心相关</h2><p>  要使用xxl-job来管理所有环境的定时任务，首先需要根据环境创建执行器群，然后在知情器群的基础上创建任务。</p>
<h3 id="创建执行器群"><a href="#创建执行器群" class="headerlink" title="创建执行器群"></a>创建执行器群</h3><p>点击web页面左侧的<strong>执行器管理</strong> =&gt; <strong>新增执行器</strong></p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1536231480/xxl-job5_virbrp.png" width="70%" height="70%"></p>
<p> 上边的<code>AppName</code>很重要，是区分各个执行器群的标志，如果选择下边的手动录入的话那么就需要将机器<code>ip:port</code>添加到机器地址中。把执行器群创建好了之后就可以创建定时任务了。</p>
<h3 id="创建定时任务"><a href="#创建定时任务" class="headerlink" title="创建定时任务"></a>创建定时任务</h3><p> 点击左侧的<strong>任务管理</strong> =&gt; <strong>新增任务</strong></p>
<p> <img src="https://res.cloudinary.com/leon824/image/upload/v1536231961/xxl-job6_iyd6r8.png" width="70%" height="70%"></p>
<p>  里边的具体选项的含义大家可以去查xxl-job的<a href="http://www.xuxueli.com/xxl-job/#/?id=%E4%B8%89%E3%80%81%E4%BB%BB%E5%8A%A1%E8%AF%A6%E8%A7%A3" target="_blank" rel="noopener">官方文档</a>，也记录的很详细。这里不在重新复述。</p>
<p>  这里还想多提一点的是他的报警机制，只支持邮件报警，但是相对来说大家打开邮件的频率比较低，平时也许不太关注邮件，所以可能导致一些任务执行失败了我们也没有及时发现。基于上面的原因，就在作者原来的代码基础上增加<strong>钉钉报警</strong>（在<code>github issues</code>中也有人提出过），实现起来也并不复杂。修改之后创建任务的时候多了两个参数，这两个参数也需要在数据库中添加两个字段。</p>
<p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1536232500/xxl-job8_fsxslg.png" width="70%" height="70%"></p>
<p>  若出现任务异常，那么会直接将自定义的信息通过<code>http post</code>的方式发送给配置的钉钉群，下面是我测试的效果。</p>
<p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1536232776/xxl-job9_vnqd4c.png" width="40%" height="40%"></p>
<h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><p>大致画了一下xxl-job的思维导图，还不够完备。</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1536114765/pic110_ugssl2.png" width="100%" height="100%"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/36627346" target="_blank" rel="noopener">美团点评许雪里：分布式任务调度平台 XXL-JOB</a></li>
<li><a href="http://www.xuxueli.com/xxl-job/#/" target="_blank" rel="noopener">xxl-job官方文档</a></li>
<li><a href="https://www.cnblogs.com/davidwang456/p/9057839.html" target="_blank" rel="noopener">分布式定时任务调度系统技术选型</a> </li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2018/09/06/分布式调度中心/" data-id="ckbyfke0d0004zbynyjaradrn" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-ELK+KAFKA详解(二)" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2018/08/25/ELK+KAFKA详解(二)/">ELK+KAFKA详解(二)</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/08/25/ELK+KAFKA详解(二)/" class="article-date">
  <time datetime="2018-08-25T05:42:14.000Z" itemprop="datePublished">2018-08-25</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/ELK/">ELK</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <p><img src="https://res.cloudinary.com/leon824/image/upload/v1535599872/pic5_pn74x6.jpg" width="80%" height="80%"></p>
<blockquote>
<p> 上一篇文章我们已经将filebeat、kafka、zookeeper、logstash安装配置完毕了。接下来主要是索引数据、展示数据阶段。</p>
</blockquote>
<hr>
<h2 id="安装Elasticsearch"><a href="#安装Elasticsearch" class="headerlink" title="安装Elasticsearch"></a>安装Elasticsearch</h2><p>首先到官网下载5.3.3版本的安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> axel -n 5 https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.3.3.tar.gz</span><br></pre></td></tr></table></figure>
<p>然后在ES的根目录下创建两个目录data、logs，用来保存索引数据、日志等等</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> mkdir logs</span><br><span class="line"><span class="meta">&gt;</span> mkdir data</span><br></pre></td></tr></table></figure>
<p>进入<code>config</code>目录编辑<code>elasticsearch.yml</code>文件，这种以.yml类型结尾的文件要注意缩进。</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Path to directory where to store the data (separate multiple locations by comma):</span></span><br><span class="line"><span class="string">path.data:</span> <span class="string">/opt/soft/elasticsearch-5.5.3/data</span></span><br><span class="line"><span class="comment"># Path to log files:</span></span><br><span class="line"><span class="string">path.logs:</span> <span class="string">/opt/soft/elasticsearch-5.5.3/logs</span></span><br><span class="line"><span class="comment"># 绑定一个指定的ip</span></span><br><span class="line"><span class="comment"># network.host: 0.0.0.0</span></span><br><span class="line"><span class="string">http.port:</span> <span class="number">9200</span></span><br><span class="line"><span class="comment"># 后边使用插件的时候需要使用到下边两个配置。</span></span><br><span class="line"><span class="string">http.cors.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">http.cors.allow-origin:</span> <span class="string">"*"</span></span><br></pre></td></tr></table></figure>
<p>上边是一些主要的配置，然后可以直接启动ES了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> ./bin/elasticsearch &amp;</span><br></pre></td></tr></table></figure>
<p>上边我们是已经启动了，但是我们还不知道数据是否通过<code>logstash</code>写入到ES中，所以我们还需要两个步骤来确保我们安装配置是没有问题的：</p>
<ul>
<li>创建一个索引（ES中的索引类似于数据库中的一个数据库实例） 。</li>
<li>安装<code>head</code>插件，查看ES情况</li>
</ul>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>在这之前我们需要了解ES中的三个基本概念：</p>
<ul>
<li>index：ES管理数据的最顶层单位，类似于单个数据库的概念。</li>
<li>document ：ES的index中单条数据被称为document</li>
<li>type：document可以分组，分组就叫type</li>
</ul>
<p>通过指定一个文件的方式创建一个索引：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span>  curl -XPUT 'http://localhost:9200/nginx_log_index/test_log/1?pretty' -H 'Content-Type: application/json' -d '/opt/soft/logstash-5.5.3/output/es_template.json'</span><br></pre></td></tr></table></figure>
<p>删除索引：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span>  curl -X DELETE 'localhost:9200/nginx_log_index'</span><br></pre></td></tr></table></figure>
<h3 id="安装head插件"><a href="#安装head插件" class="headerlink" title="安装head插件"></a>安装head插件</h3><p>head插件运行需要node环境，这里就不讨论如何安装node了，网上资料比较多。</p>
<p>使用git下载head源码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> git clone git://github.com/mobz/elasticsearch-head.git</span><br></pre></td></tr></table></figure>
<p>然后进入head的目录执行指令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> npm install</span><br></pre></td></tr></table></figure>
<p>启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; npm run start</span><br></pre></td></tr></table></figure>
<p>若是ES使用的都是默认端口，那么<code>head</code>插件就不需要修改配置。</p>
<p>在浏览器中访问<code>http://ip:9100/</code>就可以看到ES的情况</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1535186203/head_yvixk7.png" width="80%" height="80%"></p>
<h3 id="ES补充"><a href="#ES补充" class="headerlink" title="ES补充"></a>ES补充</h3><p>Elasticsearch是一个搜索引擎，我们可以通过它提供的查询语句实现类似sql的查询功能，为我们展示数据提供便利，下面列举一个常用的查询。</p>
<p>1、指定一个index，搜索其下所有type的数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> curl -X GET 'http://localhost:9200/nginx-log/_search?pretty' -H 'Content-Type: application/json' -d '  </span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match_all": &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br></pre></td></tr></table></figure>
<p>上边的nginx-log就是我们想要查询的index</p>
<p>2、查看每个index所包含的type</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> curl 'localhost:9200/_mapping?pretty=true'</span><br></pre></td></tr></table></figure>
<p>3、查看当前节点的所有Index</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> curl -X GET 'http://localhost:9200/_cat/indices?v'</span><br></pre></td></tr></table></figure>
<p>4、根据某个字段进行分组后统计，实现类似于<code>sql</code>里边的功能</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> table_name <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">field</span>;</span><br></pre></td></tr></table></figure>
<p>下面的ES查询语句功能和上边的sql是类似的</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> curl -X POST 'http://localhost:9200/nginx-log/nginxlog/_search?pretty' -H 'Content-Type: application/json' -d'</span><br><span class="line">&#123;	</span><br><span class="line">	"size": 0,</span><br><span class="line">	"aggs": &#123;</span><br><span class="line">	"group_by_service_name": &#123;</span><br><span class="line">		"terms": &#123; </span><br><span class="line">		"field": "service_name.keyword"</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="安装kibana"><a href="#安装kibana" class="headerlink" title="安装kibana"></a>安装kibana</h2><p>下载：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> axel -n 5 https://artifacts.elastic.co/downloads/kibana/kibana-5.5.3-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure>
<p>kibana的安装配置较为简单，只需要在config目录中的kibana.yml文件配置两个字段</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Kibana is served by a back end server. This setting specifies the port to use.</span></span><br><span class="line"><span class="string">server.port:</span> <span class="number">5601</span></span><br><span class="line"><span class="comment"># The URL of the Elasticsearch instance to use for all your queries.</span></span><br><span class="line"><span class="string">elasticsearch.url:</span> <span class="string">"http://localhost:9200"</span></span><br></pre></td></tr></table></figure>
<p>然后启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> ./bin/kibana &amp;</span><br></pre></td></tr></table></figure>
<p>在第一次启动kibana的时候，需要手动配置一个index，然后kibana会通过这个index去ES中查询并展示。</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1535187828/kiaban_bozs2a.png" width="80%" height="80%"></p>
<p>我们将刚才创建的index加入到里边，然后点击<code>Discover</code>选择刚才配置的index，在选择时间，就能够看到数据已经被展示出来了。</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1535203571/discoey_g4ltbs.png" width="80%" height="80%"></p>
<p>上图中的左侧可以选择在右侧展示哪些字段。</p>
<h3 id="使用kibana绘图"><a href="#使用kibana绘图" class="headerlink" title="使用kibana绘图"></a>使用kibana绘图</h3><p>&emsp;&emsp;在kibana中也是可以完成一些绘图的，但是由于kibana没有相应权限控制，并且kibana的颜值是没有Grafana高，所以我们还是用Grafana来展示图表，kibana查询日志。下面就来探讨一下Grafana相关内容</p>
<hr>
<h2 id="Grafana相关"><a href="#Grafana相关" class="headerlink" title="Grafana相关"></a>Grafana相关</h2><p>我们先进入Grafana的<a href="https://grafana.com/grafana/download" target="_blank" rel="noopener">官网</a>，里边有介绍如何安装，也很简单。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana_5.2.2_amd64.deb </span><br><span class="line"><span class="meta">&gt;</span> sudo dpkg -i grafana_5.2.2_amd64.deb</span><br></pre></td></tr></table></figure>
<p>然后启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> sudo /bin/systemctl start grafana-server</span><br></pre></td></tr></table></figure>
<p>访问<code>http://localhost:3000</code>然后使用admin登录进去，密码默认也是admin。进去后需要先配置数据源。</p>
<p><img src="https://res.cloudinary.com/leon824/image/upload/v1535204856/gra_ihk0b2.png" width="70%" height="70%"></p>
<p>  上边有几个地方需要注意：</p>
<ul>
<li>type：由于我们是使用ES作为数据源，所以这里一定要选择<code>elasticsearch</code></li>
<li>url : 连接elasticsearch服务的地址</li>
<li>Access：需要选择具体某种连接方式，两种方式是不同的，具体不同这里不详细描述</li>
<li>Auth：ES若是安装了相应密码权限，这里需要正确配置之后才能访问。</li>
<li>Index name ： 这里是填在ES中创建的index，但是要注意，若是index name包含了日志，那么后边的pattern就不要选择任何日期了。</li>
<li>Version ： 需要选择和安装的ES匹配的版本</li>
</ul>
<p>然后保存，然后就可以创建DashBoard、panel。grafana绘图、查询相关内容较多，后边若有时间还会探讨一下grafana绘图相关。</p>
<hr>
<h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><ul>
<li><a href="https://www.cnblogs.com/hupengcool/p/4031543.html" target="_blank" rel="noopener">elasticsearch 创建索引，以及检索一条数据</a></li>
<li><a href="https://grafana.com/grafana/download" target="_blank" rel="noopener">grafana官网</a></li>
<li><a href="https://groups.io/g/grafana/topic/tutorial_for_elasticsearch/716433?p=,,,20,0,0,0" target="_blank" rel="noopener">groups.io</a></li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2018/08/25/ELK+KAFKA详解(二)/" data-id="ckbyfke040000zbyna7o2ebd2" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-ELK+KAFKA详解（一）" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2018/08/22/ELK+KAFKA详解（一）/">ELK+KAFKA详解（一）</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/08/22/ELK+KAFKA详解（一）/" class="article-date">
  <time datetime="2018-08-22T02:47:17.000Z" itemprop="datePublished">2018-08-22</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/ELK/">ELK</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1535599870/pic4_vjsn1u.jpg" width="80%" height="80%"></p>
<blockquote>
<p>&emsp;&emsp;日志，对于任何系统来说都是及其重要的组成部分。在计算机系统里面，更是如此。但是由于现在的计算机系统大多比较复杂，很多系统都不是在一个地方，甚至都是跨国界的；即使是在一个地方的系统，也有不同的来源，比如，操作系统，应用服务，业务逻辑等等。他们都在不停产生各种各样的日志数据。<br> &emsp;&emsp;根据不完全统计，我们全球每天大约要产生 2EB（1018）的数据。面对如此海量的数据，又是分布在各个不同地方，如果我们需要去查找一些重要的信息，难道还是使用传统的方法，去登陆到一台台机器上查看？看来传统的工具和方法已经显得非常笨拙和低效了。于是，一些聪明人就提出了建立一套集中式的方法，把不同来源的数据集中整合到一个地方。</p>
</blockquote>
<p>一个完整的集中式日志系统，是离不开以下几个主要特点的。</p>
<ul>
<li>收集－能够采集多种来源的日志数据</li>
<li>传输－能够稳定的把日志数据传输到中央系统</li>
<li>存储－如何存储日志数据</li>
<li>分析－可以支持 UI 分析</li>
<li>警告－能够提供错误报告，监控机制</li>
</ul>
<p>本文采用ELK + FILEBEAT + KAFKA的架构搭建日志收集系统。架构图如下：</p>
<p>  <img src="https://res.cloudinary.com/leon824/image/upload/v1535176986/geranal_eugyfc.png" width="80%" height="80%"></p>
<hr>
<h3 id="环境、版本"><a href="#环境、版本" class="headerlink" title="环境、版本"></a>环境、版本</h3><ul>
<li>JDK 1.8</li>
<li>OS : ubuntu18.04</li>
<li>filebeat、logstash、elasticsearch、kibana（5.5.3）</li>
<li>kafka_2.11-0.10.0.1</li>
<li>Grafana ：Latest version</li>
</ul>
<h3 id="filebeat安装"><a href="#filebeat安装" class="headerlink" title="filebeat安装"></a>filebeat安装</h3><blockquote>
<p>  &emsp;&emsp;一个轻量级开源日志文件数据搜集器，基于Logstash-Forwarder 源代码开发，是对它的替代。在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到指定的MQ中，亦或直接发送到logstash进行过滤转发。<br>现下载到本地</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> axel -n 5 https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.3.3-linux-x86_64.tar.gz</span><br><span class="line"><span class="meta">&gt;</span> tar -zxvf  filebeat-5.5.3-linux-x86_64.tar.gz</span><br><span class="line"><span class="meta">&gt;</span> mv filebeat-5.5.3-linux-x86_64 filebeat-5.5.3</span><br></pre></td></tr></table></figure>
<p>然后进入目录中复制一份cp filebeat.yml filebeat-kafka.yml，修改文件中相应的地方。</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定输入类型</span></span><br><span class="line"><span class="attr">- input_type:</span> <span class="string">log</span> </span><br><span class="line"><span class="comment"># 需要监控的文件目录，也可以使用通配符对整个目录监控</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/opt/soft/logs/platform.pro.access.log</span></span><br><span class="line"><span class="comment">#定义kafka为输出目的地</span></span><br><span class="line"><span class="string">output.kafka:</span></span><br><span class="line">  <span class="comment"># Array of hosts to connect to.</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">["ip:9092"]</span></span><br><span class="line">  <span class="comment">#kafka的主题</span></span><br><span class="line"><span class="attr">  topic:</span> <span class="string">nginx_log</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">  processors:</span></span><br><span class="line"><span class="attr"> - drop_fields:</span></span><br><span class="line"><span class="attr">     fields:</span> <span class="string">["beat",</span> <span class="string">"input_type"</span><span class="string">,</span> <span class="string">"offset"</span><span class="string">,</span> <span class="string">"source"</span><span class="string">]</span></span><br></pre></td></tr></table></figure>
<p>需要特别注意的是上边<code>drop_fields</code>，可以在上边配置你不希望filebeat输入的字段（可以排除一些无用的信息，减少存储），可以添加<code>condition</code>条件，若是不添加条件，默认将所有声明的字段全部排除，不会将字段加入到输出流中。同时还要注意一定要将output输出目的从默认的<strong>ElasticSearch</strong>修改成<strong>kafka</strong>。 以上配置就算安装完成了。<br>接着启动.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> ./filebeat -e -c filebeat-kafka.yml</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="kafka安装配置"><a href="#kafka安装配置" class="headerlink" title="kafka安装配置"></a>kafka安装配置</h3><p>  kafka的运行依赖zookeeper，所以安装kafka之前需要先安装zookeeper，这里不用kafka自身带有的zookeeper。</p>
<h4 id="zookeeper配置"><a href="#zookeeper配置" class="headerlink" title="zookeeper配置"></a>zookeeper配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> axel -n 5 https://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</span><br><span class="line"><span class="meta">&gt;</span> tar -zxvf zookeeper-3.4.6.tar.gz</span><br></pre></td></tr></table></figure>
<p>  然后进入zookeeper目录创建两个文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> mkdir logs</span><br><span class="line"><span class="meta">&gt;</span> mkdir data</span><br></pre></td></tr></table></figure>
<p>在/root/elk/zookeeper-3.4.6/conf目录下复制zoo_sample.cfg命名为zoo.cfg</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> cp zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure>
<p>  打开zoo.cfg，修改需要配置的地方</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/opt/soft/zookeeper-3.4.6/data</span><br><span class="line">dataLogDir=/opt/soft/zookeeper-3.4.6/logs</span><br><span class="line">clientPort=2181</span><br></pre></td></tr></table></figure>
<p>在/root/elk/zookeeper-3.4.6/data目录下创建一个myid文件。由于我们这里只是单点环境下，所以只需要在文件里边写入server.1。</p>
<p> 最后将zk的路径添加到相关的环境变量中，并添加PATH,然后启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> zkServer.sh start</span><br></pre></td></tr></table></figure>
<p>最后查看zk是否启动成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> zkServer.sh status</span><br></pre></td></tr></table></figure>
<h4 id="kafka配置"><a href="#kafka配置" class="headerlink" title="kafka配置"></a>kafka配置</h4><p>安装kafka的时候需要注意和logstash之间版本匹配的问题，logstash5.x以上必须使用kakfa 0.10以上版本，否则无法正常运行。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> axel -n 5 https://archive.apache.org/dist/kafka/0.10.0.1/kafka_2.11-0.10.0.1.tgz</span><br></pre></td></tr></table></figure>
<p>下载完成之后解压、进入kafka根目录创建logs目录,然后打开config目录下的server.properties修改一些参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log.dirs=/opt/soft/kafka_2.11-0.10.0.1/logs</span><br><span class="line">zookeeper.connect=ip:2181</span><br><span class="line">其他项根据需要自行修改....</span><br></pre></td></tr></table></figure>
<p>然后可以启动kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
<p>创建一个名叫nginx_log的kafka主题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic nginx_log</span><br></pre></td></tr></table></figure>
<p>然后自己可以尝试打开一个终端进入生产者模式，发送几条数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic nginx_log</span><br></pre></td></tr></table></figure>
<p>在另外一个终端中开启消费者模式，查看生产者发送的数据是否能够看到，若能正常看到发送的数据，说明kafka安装没有问题。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic nginx_log --from-beginning</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="logstash安装配置"><a href="#logstash安装配置" class="headerlink" title="logstash安装配置"></a>logstash安装配置</h3><p> &emsp;&emsp;&ensp;记住文章开始的那张整体架构图，kafka是从filebeat接收数据，然后发送给logstash。所以这里logstash的input就是kafka了。<br> logstash是整个流程中配置、修改最多的一环，过程中也有一些坑。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> axel -n 5 https://artifacts.elastic.co/downloads/logstash/logstash-5.3.3.tar.gz</span><br></pre></td></tr></table></figure>
<p>老规矩，先解压，进入config目录创建一个logstash.conf的文件，然后在这个文件里边添加input、filter、output三个模块。</p>
<h4 id="input模块"><a href="#input模块" class="headerlink" title="input模块"></a>input模块</h4><p>先来讲讲input模块，由于在logstash5.x中已经默认支持kafka作为input,所以可以直接使用。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">    kafka&#123;</span><br><span class="line">       topics =&gt; ["nginx_log"]</span><br><span class="line">       type =&gt; "nginx-access"</span><br><span class="line">       bootstrap_servers =&gt; "ip:9092"</span><br><span class="line">       codec =&gt; "json"</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>topics :指定消费kafka的topic</li>
<li>type ： 若是logstash需要处理多个数据源，可以使用type来做后边过滤的区分。</li>
<li>bootstrap_servers ：kakfa服务的ip和端口号</li>
</ul>
<h4 id="filter模块"><a href="#filter模块" class="headerlink" title="filter模块"></a>filter模块</h4><p>&emsp;&emsp;&ensp; filter模块是具体处理数据的一个环节，当kafka的数据被input模块接收过来之后，接下来就会交给filter模块处理。这里我们是为了处理nginx的access日志，所以首先需要根据nginx的log_format来定制自己的grok正则表达式。<br>生产环境的log_format是下面这样👇</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log_format</span><br><span class="line">        '$remote_addr [$time_local] $host "$request" '</span><br><span class="line">        '$status $body_bytes_sent "$http_referer" '</span><br><span class="line">        '"$http_x_forwarded_for" "$http_user_agent" $request_time $upstream_response_time';</span><br></pre></td></tr></table></figure>
<p>实际的日志长成这样 </p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">100.116.224.17 [14/Aug/2018:07:45:49 +0800] platform.blingabc.com "POST /homeworkRecord/v1/insert HTTP/1.1" 200 517 "https://i.blingabc.com/home/read-book?stuID=11936" "27.187.252.91" "Mozilla/5.0 (iPhone; CPU iPhone OS 11_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E216 MicroMessenger/6.7.1 NetType/WIFI Language/zh_CN" 0.456 0.456</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;&ensp;当我们在做nginx日志解析的时候，尽量复用grok自身带有的。少数不能解析的根据现有修改，基本上都满足解析nginx日志。在filter模块中加入下面的配置</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">grok &#123;</span><br><span class="line">      patterns_dir =&gt; <span class="string">"/opt/soft/logstash-5.5.3/patterns/nginx_pattern"</span> </span><br><span class="line">      match =&gt; &#123;</span><br><span class="line">         <span class="string">"message"</span> =&gt; <span class="string">"%&#123;NGINXACCESS&#125;"</span></span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;&ensp;需要注意上边的patterns_dir，这个路径中patterns这个目录必须创建在logstash的根目录中且只能叫这个名字，之后的nginx_pattern可以随意取。<br>nginx_pattern文件的内容：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">STATUS ([<span class="number">0</span>-<span class="number">9</span>.]&#123;<span class="number">0</span>,<span class="number">3</span>&#125;)</span><br><span class="line">REQUEST_TIME ([<span class="number">0</span>-<span class="number">9</span>.]&#123;<span class="number">0</span>,<span class="number">5</span>&#125;)</span><br><span class="line">FORWORD (?:%&#123;IPV4&#125;[,]?[ ]?)</span><br><span class="line">NGINXACCESS %&#123;IPV4:remote_addr&#125; \[%&#123;HTTPDATE:time_local&#125;\] (%&#123;HOSTNAME:host&#125;) (%&#123;QUOTEDSTRING:request&#125;) %&#123;STATUS:http_status&#125; %&#123;BASE10NUM:body_bytes_sent&#125; \<span class="string">"(?:%&#123;DATA:http_referer&#125;|-)\" \"(%&#123;FORWORD:http_x_forwarded_for&#125;|-)\" \"(%&#123;GREEDYDATA:user_agent&#125;|-)\" (%&#123;REQUEST_TIME:request_time&#125;|-) (%&#123;REQUEST_TIME:upstream_response_time&#125;|-)</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;&ensp;其中前面三条是自己的定义的正则表达式，后边NGINXACCESS是整体解析nginx日志的表达式。在自己写解析日志的grok表达式的时候在<a href="https://grokdebug.herokuapp.com/" target="_blank" rel="noopener">Grok Debugger</a>中测试。</p>
<p><strong>最终解析出来的数据如下</strong> <em>【部分省略】</em></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"remote_addr"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"100.116.224.72"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"time_local"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"14/Aug/2018:00:20:14 +0800"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"host"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"platform.blingabc.com"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"request"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">""</span>OPTIONS /foreign/teacher/v1/login HTTP/<span class="number">1.1</span><span class="string">""</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"http_status"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"200"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"body_bytes_sent"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"0"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"http_referer"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"-"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"http_x_forwarded_for"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"181.143.78.26"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"user_agent"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"request_time"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"0.001"</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"upstream_response_time"</span>: [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">"0.001"</span></span><br><span class="line">    ]</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时我们有一个需求，需要通过下面的request解析得到/foreign/teacher/v1/login和foreign，然后通过Grafana统计做top N展示，那么数据就还需要进一步拆分。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">"request": [</span><br><span class="line">    [</span><br><span class="line">      <span class="string">""</span>OPTIONS /foreign/teacher/v1/login HTTP/<span class="number">1.1</span><span class="string">""</span></span><br><span class="line">    ]</span><br><span class="line">  ],</span><br></pre></td></tr></table></figure>
<p>filter模块中支持很多插件给我们使用，例如grok、kv、ruby、mutate等等… 下面就用ruby和mutate来实现我们想达到的目标。</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"> filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">          patterns_dir =&gt; <span class="string">"/opt/soft/logstash-5.5.3/patterns/nginx_pattern"</span> </span><br><span class="line">          match =&gt; &#123;</span><br><span class="line">             <span class="string">"message"</span> =&gt; <span class="string">"%&#123;NGINXACCESS&#125;"</span></span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="keyword">if</span> [request] &#123;</span><br><span class="line">        ruby &#123;</span><br><span class="line">            init =&gt; <span class="string">"@kname = ['method','uri']"</span></span><br><span class="line">            code =&gt; <span class="string">"</span></span><br><span class="line"><span class="string">                new_event = LogStash::Event.new(Hash[@kname.zip(event.get('request').split(' '))]) </span></span><br><span class="line"><span class="string">                new_event.remove('@timestamp')</span></span><br><span class="line"><span class="string">                event.append(new_event)</span></span><br><span class="line"><span class="string">            "</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> [uri] &#123;</span><br><span class="line">            ruby &#123;</span><br><span class="line">                init =&gt; <span class="string">"@kname = ['url_path','url_args']"</span></span><br><span class="line">                code =&gt; <span class="string">"</span></span><br><span class="line"><span class="string">                    new_event = LogStash::Event.new(Hash[@kname.zip(event.get('uri').split('?'))])</span></span><br><span class="line"><span class="string">                    new_event.remove('@timestamp')</span></span><br><span class="line"><span class="string">                    event.append(new_event)</span></span><br><span class="line"><span class="string">                "</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">   <span class="keyword">if</span> [url_path] &#123;</span><br><span class="line">            ruby &#123;</span><br><span class="line">                init =&gt; <span class="string">"@kname = ['service_name', 'url_path']"</span></span><br><span class="line">                code =&gt; <span class="string">"</span></span><br><span class="line"><span class="string">                    new_event = LogStash::Event.new(Hash[@kname.zip(event.get('uri').split('/'))])</span></span><br><span class="line"><span class="string">                    new_event.remove('@timestamp')</span></span><br><span class="line"><span class="string">                    event.append(new_event)</span></span><br><span class="line"><span class="string">                "</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;   </span><br><span class="line">    mutate &#123;</span><br><span class="line">            rename =&gt; [<span class="string">"url_path[1]"</span>, <span class="string">"service_name"</span>]</span><br><span class="line">	    rename =&gt; [<span class="string">"url_path[0]"</span>, <span class="string">"uri"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> [service_name] == <span class="string">"monitor"</span> <span class="keyword">or</span> [service_name] == <span class="string">"weixin"</span> <span class="keyword">or</span> [method] == <span class="string">"OPTIONS"</span> &#123;</span><br><span class="line">            drop &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上边的执行时流式执行的，就是说上边执行得到的结果下边可以直接使用。然后将数组里边的结果重名名，提供给下面ES使用。</p>
<h4 id="output"><a href="#output" class="headerlink" title="output"></a>output</h4><p>最后就是output模块了，这里比较简单，主要是讲过滤后的数据交给ES。</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">        elasticsearch&#123;</span><br><span class="line">        hosts =&gt; [<span class="string">"ip:9200"</span>]</span><br><span class="line">        index =&gt; <span class="string">"nginx-log"</span></span><br><span class="line">        template_overwrite =&gt; <span class="literal">true</span></span><br><span class="line">        template =&gt; <span class="string">"/opt/soft/logstash-5.5.3/output/es_template.json"</span></span><br><span class="line">        &#125;</span><br><span class="line">        stdout&#123;codec =&gt; rubydebug&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是需要注意上边的template指定的文件，在es_template.json这个文件中定义了filter模块解析出来的字段名称、类型。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"template"</span>:<span class="string">"nginx-log"</span>,</span><br><span class="line">    <span class="attr">"settings"</span>:&#123;</span><br><span class="line">        <span class="attr">"index.refresh_interval"</span>:<span class="string">"5s"</span>,</span><br><span class="line">        <span class="attr">"index.number_of_replicas"</span>:<span class="string">"1"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"analysis"</span>:&#123;</span><br><span class="line">        <span class="attr">"analyzer"</span>:&#123;</span><br><span class="line">            <span class="attr">"default"</span>:&#123;</span><br><span class="line">                <span class="attr">"type"</span>:<span class="string">"standard"</span>,</span><br><span class="line">                <span class="attr">"stopwords"</span>:<span class="string">"_none_"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"mappings"</span>:&#123;</span><br><span class="line">        <span class="attr">"nginx_log"</span>:&#123;</span><br><span class="line">            <span class="attr">"_all"</span>:&#123;</span><br><span class="line">                <span class="attr">"enabled"</span>:<span class="literal">false</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"properties"</span>:&#123;</span><br><span class="line">                <span class="attr">"remote_addr"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"ip"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"time_local"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"date"</span>,</span><br><span class="line">                    <span class="attr">"format"</span>:<span class="string">"dd/MMM/yyyy:HH:mm:ss Z"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"host"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"string"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;,</span><br><span class="line">		<span class="attr">"uri"</span>:&#123;</span><br><span class="line">		    <span class="attr">"type"</span>:<span class="string">"string"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">		&#125;,</span><br><span class="line">                <span class="attr">"request"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"string"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"http_status"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"integer"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"body_bytes_sent"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"integer"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"http_referer"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"string"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"http_x_forwarded_for"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"ip"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"user_agent"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"string"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"request_time"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"float"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"upstream_response_time"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"float"</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"service_name"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"string"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"request_url"</span>:&#123;</span><br><span class="line">                    <span class="attr">"type"</span>:<span class="string">"string"</span>,</span><br><span class="line">		    <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">"geoip"</span>:&#123;</span><br><span class="line">                    <span class="attr">"properties"</span>:&#123;</span><br><span class="line">                        <span class="attr">"city_name"</span>:&#123;</span><br><span class="line">                            <span class="attr">"type"</span>:<span class="string">"keyword"</span></span><br><span class="line">                        &#125;,</span><br><span class="line">                        <span class="attr">"country_name"</span>:&#123;</span><br><span class="line">                            <span class="attr">"type"</span>:<span class="string">"keyword"</span></span><br><span class="line">                        &#125;,</span><br><span class="line">                        <span class="attr">"latitude"</span>:&#123;</span><br><span class="line">                            <span class="attr">"type"</span>:<span class="string">"float"</span></span><br><span class="line">                        &#125;,</span><br><span class="line">                        <span class="attr">"location"</span>:&#123;</span><br><span class="line">                            <span class="attr">"type"</span>:<span class="string">"geo_point"</span></span><br><span class="line">                        &#125;,</span><br><span class="line">                        <span class="attr">"longitude"</span>:&#123;</span><br><span class="line">                            <span class="attr">"type"</span>:<span class="string">"float"</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终形成的配置文件就是这样的</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">    kafka&#123;</span><br><span class="line">       topics =&gt; [<span class="string">"nginx_log"</span>]</span><br><span class="line">       type =&gt; <span class="string">"nginx-access"</span></span><br><span class="line">       bootstrap_servers =&gt; <span class="string">"ip:9092"</span></span><br><span class="line">       codec =&gt; <span class="string">"json"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">          patterns_dir =&gt; <span class="string">"/opt/soft/logstash-5.5.3/patterns/nginx_pattern"</span> </span><br><span class="line">          match =&gt; &#123;</span><br><span class="line">             <span class="string">"message"</span> =&gt; <span class="string">"%&#123;NGINXACCESS&#125;"</span></span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="keyword">if</span> [request] &#123;</span><br><span class="line">        ruby &#123;</span><br><span class="line">            init =&gt; <span class="string">"@kname = ['method','uri']"</span></span><br><span class="line">            code =&gt; <span class="string">"</span></span><br><span class="line"><span class="string">                new_event = LogStash::Event.new(Hash[@kname.zip(event.get('request').split(' '))]) </span></span><br><span class="line"><span class="string">                new_event.remove('@timestamp')</span></span><br><span class="line"><span class="string">                event.append(new_event)</span></span><br><span class="line"><span class="string">            "</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> [uri] &#123;</span><br><span class="line">            ruby &#123;</span><br><span class="line">                init =&gt; <span class="string">"@kname = ['url_path','url_args']"</span></span><br><span class="line">                code =&gt; <span class="string">"</span></span><br><span class="line"><span class="string">                    new_event = LogStash::Event.new(Hash[@kname.zip(event.get('uri').split('?'))])</span></span><br><span class="line"><span class="string">                    new_event.remove('@timestamp')</span></span><br><span class="line"><span class="string">                    event.append(new_event)</span></span><br><span class="line"><span class="string">                "</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">   <span class="keyword">if</span> [url_path] &#123;</span><br><span class="line">            ruby &#123;</span><br><span class="line">                init =&gt; <span class="string">"@kname = ['service_name', 'url_path']"</span></span><br><span class="line">                code =&gt; <span class="string">"</span></span><br><span class="line"><span class="string">                    new_event = LogStash::Event.new(Hash[@kname.zip(event.get('uri').split('/'))])</span></span><br><span class="line"><span class="string">                    new_event.remove('@timestamp')</span></span><br><span class="line"><span class="string">                    event.append(new_event)</span></span><br><span class="line"><span class="string">                "</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;   </span><br><span class="line">    mutate &#123;</span><br><span class="line">            rename =&gt; [<span class="string">"url_path[1]"</span>, <span class="string">"service_name"</span>]</span><br><span class="line">	    rename =&gt; [<span class="string">"url_path[0]"</span>, <span class="string">"uri"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> [service_name] == <span class="string">"monitor"</span> <span class="keyword">or</span> [service_name] == <span class="string">"weixin"</span> <span class="keyword">or</span> [method] == <span class="string">"OPTIONS"</span> &#123;</span><br><span class="line">            drop &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">        elasticsearch&#123;</span><br><span class="line">        hosts =&gt; [<span class="string">"localhost:9200"</span>]</span><br><span class="line">        index =&gt; <span class="string">"nginx-log"</span></span><br><span class="line">        template_overwrite =&gt; <span class="literal">true</span></span><br><span class="line">        template =&gt; <span class="string">"/opt/soft/logstash-5.5.3/output/es_template.json"</span></span><br><span class="line">        &#125;</span><br><span class="line">	stdout&#123;codec =&gt; rubydebug&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上边已经整个环境搭建完成了一大半了，接下来就是安装Elasticsearch和kibana、Grafana。</p>
<h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><ul>
<li><a href="https://segmentfault.com/a/1190000011263254" target="_blank" rel="noopener">ELK初体验-Nginx日志实时分析</a></li>
<li><a href="http://blog.51cto.com/zero01/2079879" target="_blank" rel="noopener">搭建ELK日志分析平台（上）</a></li>
<li><a href="https://www.jianshu.com/p/6b7f0488ddff" target="_blank" rel="noopener">elk搭建实战</a></li>
<li><a href="https://my.oschina.net/itblog/blog/547250" target="_blank" rel="noopener">ELK(ElasticSearch, Logstash, Kibana)搭建实时日志分析平台</a></li>
</ul>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2018/08/22/ELK+KAFKA详解（一）/" data-id="ckbyfke0a0001zbynxpp5kumd" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
          <article id="post-java 工程师成神之路(转载)" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h2 itemprop="name">
      <a class="article-title" href="/2018/06/28/java 工程师成神之路(转载)/">java 工程师成神之路(转载)</a>
    </h2>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/06/28/java 工程师成神之路(转载)/" class="article-date">
  <time datetime="2018-06-28T02:03:37.000Z" itemprop="datePublished">2018-06-28</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/java/">java</a>
  </div>

                    </div>
                    

                        

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <blockquote>
<p>今天在论坛上看到的一个帖子，上边提到的内容极为宽泛，可能在短时间内不可能完全做到提到的所有内容，但也不妨作为一个学习的目标。<br><a href="https://www.v2ex.com/t/466451#reply2" target="_blank" rel="noopener">原文地址</a></p>
</blockquote>
<h3 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h3><h4 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h4><h5 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h5><p>堆、栈、方法区、直接内存、堆和栈区别</p>
<h5 id="Java-内存模型"><a href="#Java-内存模型" class="headerlink" title="Java 内存模型"></a>Java 内存模型</h5><p>内存可见性、重排序、顺序一致性、volatile、锁、final</p>
<h5 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h5><p>内存分配策略、垃圾收集器（ G1 ）、GC 算法、GC 参数、对象存活的判定</p>
<h5 id="JVM-参数及调优"><a href="#JVM-参数及调优" class="headerlink" title="JVM 参数及调优"></a>JVM 参数及调优</h5><h5 id="Java-对象模型"><a href="#Java-对象模型" class="headerlink" title="Java 对象模型"></a>Java 对象模型</h5><p>oop-klass、对象头</p>
<h5 id="HotSpot"><a href="#HotSpot" class="headerlink" title="HotSpot"></a>HotSpot</h5><p>即时编译器、编译优化</p>
<h5 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h5><p>classLoader、类加载过程、双亲委派（破坏双亲委派）、模块化（ jboss modules、osgi、jigsaw ）</p>
<h5 id="虚拟机性能监控与故障处理工具"><a href="#虚拟机性能监控与故障处理工具" class="headerlink" title="虚拟机性能监控与故障处理工具"></a>虚拟机性能监控与故障处理工具</h5><p> jps, jstack, jmap、jstat, jconsole, jinfo, jhat, javap, btrace、TProfiler</p>
<p>编译与反编译</p>
<p>javac、javap、jad、CRF</p>
<h4 id="Java-基础知识"><a href="#Java-基础知识" class="headerlink" title="Java 基础知识"></a>Java 基础知识</h4><h6 id="阅读源代码"><a href="#阅读源代码" class="headerlink" title="阅读源代码"></a>阅读源代码</h6><p>String、Integer、Long、Enum、BigDecimal、ThreadLocal、ClassLoader &amp; URLClassLoader、ArrayList &amp; LinkedList、HashMap &amp; LinkedHashMap &amp; TreeMap &amp; CouncurrentHashMap、HashSet &amp; LinkedHashSet &amp; TreeSet</p>
<h5 id="Java中各种变量类型"><a href="#Java中各种变量类型" class="headerlink" title="Java中各种变量类型"></a>Java中各种变量类型</h5><h5 id="熟悉-Java-String-的使用，熟悉-String-的各种函数"><a href="#熟悉-Java-String-的使用，熟悉-String-的各种函数" class="headerlink" title="熟悉 Java String 的使用，熟悉 String 的各种函数"></a>熟悉 Java String 的使用，熟悉 String 的各种函数</h5><p>JDK 6 和 JDK 7 中 substring 的原理及区别、</p>
<p>replaceFirst、replaceAll、replace 区别、</p>
<p>String 对“+”的重载、</p>
<p>String.valueOf 和 Integer.toString 的区别、</p>
<p>字符串的不可变性</p>
<p>自动拆装箱</p>
<p>Integer 的缓存机制</p>
<h5 id="熟悉-Java-中各种关键字"><a href="#熟悉-Java-中各种关键字" class="headerlink" title="熟悉 Java 中各种关键字"></a>熟悉 Java 中各种关键字</h5><p>transient、instanceof、volatile、synchronized、final、static、const 原理及用法。</p>
<h5 id="集合类"><a href="#集合类" class="headerlink" title="集合类"></a>集合类</h5><p>常用集合类的使用、ArrayList 和 LinkedList 和 Vector 的区别 、SynchronizedList 和 Vector 的区别、HashMap、HashTable、ConcurrentHashMap 区别、Java 8 中 stream 相关用法、apache 集合处理工具类的使用、不同版本的 JDK 中 HashMap 的实现的区别以及原因</p>
<h5 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h5><p>枚举的用法、枚举与单例、Enum 类</p>
<h5 id="Java-IO-amp-Java-NIO，并学会使用"><a href="#Java-IO-amp-Java-NIO，并学会使用" class="headerlink" title="Java IO&amp;Java NIO，并学会使用"></a>Java IO&amp;Java NIO，并学会使用</h5><p>bio、nio 和 aio 的区别、三种 IO 的用法与原理、netty</p>
<h5 id="Java-反射与-javassist"><a href="#Java-反射与-javassist" class="headerlink" title="Java 反射与 javassist"></a>Java 反射与 javassist</h5><p>反射与工厂模式、 java.lang.reflect.*</p>
<h5 id="Java-序列化"><a href="#Java-序列化" class="headerlink" title="Java 序列化"></a>Java 序列化</h5><p>什么是序列化与反序列化、为什么序列化、序列化底层原理、序列化与单例模式、protobuf、为什么说序列化并不安全</p>
<h5 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h5><p>元注解、自定义注解、Java 中常用注解使用、注解与反射的结合</p>
<h5 id="JMS"><a href="#JMS" class="headerlink" title="JMS"></a>JMS</h5><p>什么是 Java 消息服务、JMS 消息传送模型</p>
<h5 id="JMX"><a href="#JMX" class="headerlink" title="JMX"></a>JMX</h5><p>java.lang.management.<em>、 javax.management.</em></p>
<h4 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h4><p>泛型与继承、类型擦除、泛型中 K T V E ？ object 等的含义、泛型各种用法</p>
<h5 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h5><p>junit、mock、mockito、内存数据库（ h2 ）</p>
<h5 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h5><p>java.lang.util.regex.*</p>
<h5 id="常用的-Java-工具库"><a href="#常用的-Java-工具库" class="headerlink" title="常用的 Java 工具库"></a>常用的 Java 工具库</h5><p>commons.lang, commons.*… guava-libraries netty</p>
<h5 id="什么是-API-amp-SPI"><a href="#什么是-API-amp-SPI" class="headerlink" title="什么是 API&amp;SPI"></a>什么是 API&amp;SPI</h5><h5 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h5><p>异常类型、正确处理异常、自定义异常</p>
<h5 id="时间处理"><a href="#时间处理" class="headerlink" title="时间处理"></a>时间处理</h5><p>时区、时令、Java 中时间 API</p>
<h5 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h5><p>解决乱码问题、常用编码方式</p>
<h5 id="语法糖"><a href="#语法糖" class="headerlink" title="语法糖"></a>语法糖</h5><p>Java 中语法糖原理、解语法糖</p>
<h4 id="Java-并发编程"><a href="#Java-并发编程" class="headerlink" title="Java 并发编程"></a>Java 并发编程</h4><h5 id="什么是线程，与进程的区别"><a href="#什么是线程，与进程的区别" class="headerlink" title="什么是线程，与进程的区别"></a>什么是线程，与进程的区别</h5><h5 id="阅读源代码，并学会使用"><a href="#阅读源代码，并学会使用" class="headerlink" title="阅读源代码，并学会使用"></a>阅读源代码，并学会使用</h5><p>Thread、Runnable、Callable、ReentrantLock、ReentrantReadWriteLock、Atomic*、Semaphore、CountDownLatch、、ConcurrentHashMap、Executors</p>
<h5 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h5><p>自己设计线程池、submit() 和 execute()</p>
<h5 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h5><p>死锁、死锁如何排查、Java 线程调度、线程安全和内存模型的关系</p>
<h5 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h5><p>CAS、乐观锁与悲观锁、数据库相关锁机制、分布式锁、偏向锁、轻量级锁、重量级锁、monitor、锁优化、锁消除、锁粗化、自旋锁、可重入锁、阻塞锁、死锁</p>
<h5 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h5><h5 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h5><h5 id="happens-before、编译器指令重排和-CPU-指令重"><a href="#happens-before、编译器指令重排和-CPU-指令重" class="headerlink" title="happens-before、编译器指令重排和 CPU 指令重"></a>happens-before、编译器指令重排和 CPU 指令重</h5><h5 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h5><p>synchronized 是如何实现的？ synchronized 和 lock 之间关系、不使用 synchronized 如何实现一个线程安全的单例</p>
<h5 id="sleep-和-wait"><a href="#sleep-和-wait" class="headerlink" title="sleep 和 wait"></a>sleep 和 wait</h5><h5 id="wait-和-notify"><a href="#wait-和-notify" class="headerlink" title="wait 和 notify"></a>wait 和 notify</h5><h5 id="notify-和-notifyAll"><a href="#notify-和-notifyAll" class="headerlink" title="notify 和 notifyAll"></a>notify 和 notifyAll</h5><h5 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h5><h5 id="写一个死锁的程序"><a href="#写一个死锁的程序" class="headerlink" title="写一个死锁的程序"></a>写一个死锁的程序</h5><h5 id="写代码来解决生产者消费者问题"><a href="#写代码来解决生产者消费者问题" class="headerlink" title="写代码来解决生产者消费者问题"></a>写代码来解决生产者消费者问题</h5><h5 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h5><h5 id="守护线程和非守护线程的区别以及用法"><a href="#守护线程和非守护线程的区别以及用法" class="headerlink" title="守护线程和非守护线程的区别以及用法"></a>守护线程和非守护线程的区别以及用法</h5><h3 id="进阶篇"><a href="#进阶篇" class="headerlink" title="进阶篇"></a>进阶篇</h3><h4 id="Java-底层知识"><a href="#Java-底层知识" class="headerlink" title="Java 底层知识"></a>Java 底层知识</h4><h5 id="字节码、class-文件格式"><a href="#字节码、class-文件格式" class="headerlink" title="字节码、class 文件格式"></a>字节码、class 文件格式</h5><h5 id="CPU-缓存，L1，L2，L3-和伪共享"><a href="#CPU-缓存，L1，L2，L3-和伪共享" class="headerlink" title="CPU 缓存，L1，L2，L3 和伪共享"></a>CPU 缓存，L1，L2，L3 和伪共享</h5><h5 id="尾递归"><a href="#尾递归" class="headerlink" title="尾递归"></a>尾递归</h5><h5 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h5><h5 id="用位运算实现加、减、乘、除、取余"><a href="#用位运算实现加、减、乘、除、取余" class="headerlink" title="用位运算实现加、减、乘、除、取余"></a>用位运算实现加、减、乘、除、取余</h5><h4 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h4><h5 id="了解-23-种设计模式"><a href="#了解-23-种设计模式" class="headerlink" title="了解 23 种设计模式"></a>了解 23 种设计模式</h5><p>会使用常用设计模式<br>单例、策略、工厂、适配器、责任链。</p>
<h5 id="实现-AOP"><a href="#实现-AOP" class="headerlink" title="实现 AOP"></a>实现 AOP</h5><h5 id="实现-IOC"><a href="#实现-IOC" class="headerlink" title="实现 IOC"></a>实现 IOC</h5><h5 id="不用-synchronized-和-lock，实现线程安全的单例模式"><a href="#不用-synchronized-和-lock，实现线程安全的单例模式" class="headerlink" title="不用 synchronized 和 lock，实现线程安全的单例模式"></a>不用 synchronized 和 lock，实现线程安全的单例模式</h5><h5 id="nio-和-reactor-设计模式"><a href="#nio-和-reactor-设计模式" class="headerlink" title="nio 和 reactor 设计模式"></a>nio 和 reactor 设计模式</h5><h4 id="网络编程知识"><a href="#网络编程知识" class="headerlink" title="网络编程知识"></a>网络编程知识</h4><h5 id="tcp、udp、http、https-等常用协议"><a href="#tcp、udp、http、https-等常用协议" class="headerlink" title="tcp、udp、http、https 等常用协议"></a>tcp、udp、http、https 等常用协议</h5><p>三次握手与四次关闭、流量控制和拥塞控制、OSI 七层模型、tcp 粘包与拆包</p>
<h5 id="http-1-0-http-1-1-http-2-之前的区别"><a href="#http-1-0-http-1-1-http-2-之前的区别" class="headerlink" title="http/1.0 http/1.1 http/2 之前的区别"></a>http/1.0 http/1.1 http/2 之前的区别</h5><h5 id="Java-RMI，Socket，HttpClient"><a href="#Java-RMI，Socket，HttpClient" class="headerlink" title="Java RMI，Socket，HttpClient"></a>Java RMI，Socket，HttpClient</h5><h5 id="cookie-与-session"><a href="#cookie-与-session" class="headerlink" title="cookie 与 session"></a>cookie 与 session</h5><p>cookie 被禁用，如何实现 session</p>
<h5 id="用-Java-写一个简单的静态文件的-HTTP-服务器"><a href="#用-Java-写一个简单的静态文件的-HTTP-服务器" class="headerlink" title="用 Java 写一个简单的静态文件的 HTTP 服务器"></a>用 Java 写一个简单的静态文件的 HTTP 服务器</h5><p>实现客户端缓存功能，支持返回 304 实现可并发下载一个文件 使用线程池处理客户端请求 使用 nio 处理客户端请求 支持简单的 rewrite 规则 上述功能在实现的时候需要满足“开闭原则”</p>
<h5 id="了解-nginx-和-apache-服务器的特性并搭建一个对应的服务器"><a href="#了解-nginx-和-apache-服务器的特性并搭建一个对应的服务器" class="headerlink" title="了解 nginx 和 apache 服务器的特性并搭建一个对应的服务器"></a>了解 nginx 和 apache 服务器的特性并搭建一个对应的服务器</h5><h5 id="用-Java-实现-FTP、SMTP-协议"><a href="#用-Java-实现-FTP、SMTP-协议" class="headerlink" title="用 Java 实现 FTP、SMTP 协议"></a>用 Java 实现 FTP、SMTP 协议</h5><h5 id="进程间通讯的方式"><a href="#进程间通讯的方式" class="headerlink" title="进程间通讯的方式"></a>进程间通讯的方式</h5><h5 id="什么是-CDN-？如果实现？"><a href="#什么是-CDN-？如果实现？" class="headerlink" title="什么是 CDN ？如果实现？"></a>什么是 CDN ？如果实现？</h5><h5 id="什么是-DNS-？"><a href="#什么是-DNS-？" class="headerlink" title="什么是 DNS ？"></a>什么是 DNS ？</h5><h5 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h5><h4 id="框架知识"><a href="#框架知识" class="headerlink" title="框架知识"></a>框架知识</h4><h5 id="Servlet-线程安全问题"><a href="#Servlet-线程安全问题" class="headerlink" title="Servlet 线程安全问题"></a>Servlet 线程安全问题</h5><h5 id="Servlet-中的-filter-和-listener"><a href="#Servlet-中的-filter-和-listener" class="headerlink" title="Servlet 中的 filter 和 listener"></a>Servlet 中的 filter 和 listener</h5><h5 id="Hibernate-的缓存机制"><a href="#Hibernate-的缓存机制" class="headerlink" title="Hibernate 的缓存机制"></a>Hibernate 的缓存机制</h5><h5 id="Hiberate-的懒加载"><a href="#Hiberate-的懒加载" class="headerlink" title="Hiberate 的懒加载"></a>Hiberate 的懒加载</h5><h5 id="Spring-Bean-的初始化"><a href="#Spring-Bean-的初始化" class="headerlink" title="Spring Bean 的初始化"></a>Spring Bean 的初始化</h5><h5 id="Spring-的-AOP-原理"><a href="#Spring-的-AOP-原理" class="headerlink" title="Spring 的 AOP 原理"></a>Spring 的 AOP 原理</h5><h5 id="自己实现-Spring-的-IOC"><a href="#自己实现-Spring-的-IOC" class="headerlink" title="自己实现 Spring 的 IOC"></a>自己实现 Spring 的 IOC</h5><h5 id="Spring-MVC"><a href="#Spring-MVC" class="headerlink" title="Spring MVC"></a>Spring MVC</h5><h5 id="Spring-Boot2-0"><a href="#Spring-Boot2-0" class="headerlink" title="Spring Boot2.0"></a>Spring Boot2.0</h5><h5 id="Spring-Boot-的-starter-原理，自己实现一个-starter"><a href="#Spring-Boot-的-starter-原理，自己实现一个-starter" class="headerlink" title="Spring Boot 的 starter 原理，自己实现一个 starter"></a>Spring Boot 的 starter 原理，自己实现一个 starter</h5><h5 id="Spring-Security"><a href="#Spring-Security" class="headerlink" title="Spring Security"></a>Spring Security</h5><p>应用服务器知识</p>
<h5 id="JBoss"><a href="#JBoss" class="headerlink" title="JBoss"></a>JBoss</h5><h5 id="tomcat"><a href="#tomcat" class="headerlink" title="tomcat"></a>tomcat</h5><h5 id="jetty"><a href="#jetty" class="headerlink" title="jetty"></a>jetty</h5><h5 id="Weblogic"><a href="#Weblogic" class="headerlink" title="Weblogic"></a>Weblogic</h5><h4 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h4><h5 id="git-amp-svn"><a href="#git-amp-svn" class="headerlink" title="git &amp; svn"></a>git &amp; svn</h5><h5 id="maven-amp-gradle"><a href="#maven-amp-gradle" class="headerlink" title="maven &amp; gradle"></a>maven &amp; gradle</h5><h4 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h4><h3 id="高级篇"><a href="#高级篇" class="headerlink" title="高级篇"></a>高级篇</h3><h4 id="新技术"><a href="#新技术" class="headerlink" title="新技术"></a>新技术</h4><h5 id="java8"><a href="#java8" class="headerlink" title="java8"></a>java8</h5><p> lambda 表达式、Stream API、</p>
<h5 id="Java-9"><a href="#Java-9" class="headerlink" title="Java 9"></a>Java 9</h5><p>Jigsaw、Jshell、Reactive Streams</p>
<h5 id="Java-10"><a href="#Java-10" class="headerlink" title="Java 10"></a>Java 10</h5><p>局部变量类型推断、G1 的并行 Full GC、ThreadLocal 握手机制</p>
<h5 id="Spring-5"><a href="#Spring-5" class="headerlink" title="Spring 5"></a>Spring 5</h5><p>响应式编程</p>
<h5 id="Spring-Boot-2-0"><a href="#Spring-Boot-2-0" class="headerlink" title="Spring Boot 2.0"></a>Spring Boot 2.0</h5><p>性能优化<br>使用单例、使用 Future 模式、使用线程池、选择就绪、减少上下文切换、减少锁粒度、数据压缩、结果缓存</p>
<h4 id="线上问题分析"><a href="#线上问题分析" class="headerlink" title="线上问题分析"></a>线上问题分析</h4><h5 id="dump-获取"><a href="#dump-获取" class="headerlink" title="dump 获取"></a>dump 获取</h5><p>线程 Dump、内存 Dump、gc 情况</p>
<h5 id="dump-分析"><a href="#dump-分析" class="headerlink" title="dump 分析"></a>dump 分析</h5><p>分析死锁、分析内存泄露</p>
<h5 id="自己编写各种-outofmemory，stackoverflow-程序"><a href="#自己编写各种-outofmemory，stackoverflow-程序" class="headerlink" title="自己编写各种 outofmemory，stackoverflow 程序"></a>自己编写各种 outofmemory，stackoverflow 程序</h5><p>HeapOutOfMemory、Young OutOfMemory、MethodArea OutOfMemory、ConstantPool OutOfMemory、DirectMemory OutOfMemory、Stack OutOfMemory Stack OverFlow</p>
<h5 id="常见问题解决思路"><a href="#常见问题解决思路" class="headerlink" title="常见问题解决思路"></a>常见问题解决思路</h5><p>内存溢出、线程死锁、类加载冲突</p>
<h5 id="使用工具尝试解决以下问题，并写下总结"><a href="#使用工具尝试解决以下问题，并写下总结" class="headerlink" title="使用工具尝试解决以下问题，并写下总结"></a>使用工具尝试解决以下问题，并写下总结</h5><p>当一个 Java 程序响应很慢时如何查找问题、</p>
<p>当一个 Java 程序频繁 FullGC 时如何解决问题、</p>
<p>如何查看垃圾回收日志、</p>
<p>当一个 Java 应用发生 OutOfMemory 时该如何解决、</p>
<p>如何判断是否出现死锁、</p>
<p>如何判断是否存在内存泄露</p>
<h4 id="编译原理知识"><a href="#编译原理知识" class="headerlink" title="编译原理知识"></a>编译原理知识</h4><h5 id="编译与反编译"><a href="#编译与反编译" class="headerlink" title="编译与反编译"></a>编译与反编译</h5><h5 id="Java-代码的编译与反编译"><a href="#Java-代码的编译与反编译" class="headerlink" title="Java 代码的编译与反编译"></a>Java 代码的编译与反编译</h5><h5 id="Java-的反编译工具"><a href="#Java-的反编译工具" class="headerlink" title="Java 的反编译工具"></a>Java 的反编译工具</h5><h5 id="词法分析，语法分析（-LL-算法，递归下降算法，LR-算法），语义分析，运行时环境，中间代码，代码生成，代码优化"><a href="#词法分析，语法分析（-LL-算法，递归下降算法，LR-算法），语义分析，运行时环境，中间代码，代码生成，代码优化" class="headerlink" title="词法分析，语法分析（ LL 算法，递归下降算法，LR 算法），语义分析，运行时环境，中间代码，代码生成，代码优化"></a>词法分析，语法分析（ LL 算法，递归下降算法，LR 算法），语义分析，运行时环境，中间代码，代码生成，代码优化</h5><h4 id="操作系统知识"><a href="#操作系统知识" class="headerlink" title="操作系统知识"></a>操作系统知识</h4><h5 id="Linux-的常用命令"><a href="#Linux-的常用命令" class="headerlink" title="Linux 的常用命令"></a>Linux 的常用命令</h5><h5 id="进程同步"><a href="#进程同步" class="headerlink" title="进程同步"></a>进程同步</h5><h5 id="缓冲区溢出"><a href="#缓冲区溢出" class="headerlink" title="缓冲区溢出"></a>缓冲区溢出</h5><h5 id="分段和分页"><a href="#分段和分页" class="headerlink" title="分段和分页"></a>分段和分页</h5><h5 id="虚拟内存与主存"><a href="#虚拟内存与主存" class="headerlink" title="虚拟内存与主存"></a>虚拟内存与主存</h5><h4 id="数据库知识"><a href="#数据库知识" class="headerlink" title="数据库知识"></a>数据库知识</h4><h5 id="MySql-执行引擎"><a href="#MySql-执行引擎" class="headerlink" title="MySql 执行引擎"></a>MySql 执行引擎</h5><h5 id="MySQL-执行计划"><a href="#MySQL-执行计划" class="headerlink" title="MySQL 执行计划"></a>MySQL 执行计划</h5><h5 id="如何查看执行计划，如何根据执行计划进行-SQL-优化"><a href="#如何查看执行计划，如何根据执行计划进行-SQL-优化" class="headerlink" title="如何查看执行计划，如何根据执行计划进行 SQL 优化"></a>如何查看执行计划，如何根据执行计划进行 SQL 优化</h5><h4 id="SQL-优化"><a href="#SQL-优化" class="headerlink" title="SQL 优化"></a>SQL 优化</h4><h5 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h5><p>事务的隔离级别、事务能不能实现锁的功能</p>
<h5 id="数据库锁"><a href="#数据库锁" class="headerlink" title="数据库锁"></a>数据库锁</h5><p>行锁、表锁、使用数据库锁实现乐观锁、</p>
<h5 id="数据库主备搭建"><a href="#数据库主备搭建" class="headerlink" title="数据库主备搭建"></a>数据库主备搭建</h5><h5 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h5><h5 id="内存数据库"><a href="#内存数据库" class="headerlink" title="内存数据库"></a>内存数据库</h5><p>h2</p>
<h5 id="常用的-nosql-数据库"><a href="#常用的-nosql-数据库" class="headerlink" title="常用的 nosql 数据库"></a>常用的 nosql 数据库</h5><p>redis、memcached</p>
<h5 id="分别使用数据库锁、NoSql-实现分布式锁"><a href="#分别使用数据库锁、NoSql-实现分布式锁" class="headerlink" title="分别使用数据库锁、NoSql 实现分布式锁"></a>分别使用数据库锁、NoSql 实现分布式锁</h5><h5 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h5><h4 id="数据结构与算法知识"><a href="#数据结构与算法知识" class="headerlink" title="数据结构与算法知识"></a>数据结构与算法知识</h4><h5 id="简单的数据结构"><a href="#简单的数据结构" class="headerlink" title="简单的数据结构"></a>简单的数据结构</h5><h5 id="栈、队列、链表、数组、哈希表、"><a href="#栈、队列、链表、数组、哈希表、" class="headerlink" title="栈、队列、链表、数组、哈希表、"></a>栈、队列、链表、数组、哈希表、</h5><h5 id="树"><a href="#树" class="headerlink" title="树"></a>树</h5><p>二叉树、字典树、平衡树、排序树、B 树、B+树、R 树、多路树、红黑树</p>
<h5 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h5><p>各种排序算法和时间复杂度 深度优先和广度优先搜索 全排列、贪心算法、KMP 算法、hash 算法、海量数据处理</p>
<h4 id="大数据知识"><a href="#大数据知识" class="headerlink" title="大数据知识"></a>大数据知识</h4><h5 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h5><p>基本概念、常见用法</p>
<h5 id="Solr，Lucene，ElasticSearch"><a href="#Solr，Lucene，ElasticSearch" class="headerlink" title="Solr，Lucene，ElasticSearch"></a>Solr，Lucene，ElasticSearch</h5><p>在 linux 上部署 solr，solrcloud，，新增、删除、查询索引</p>
<h5 id="Storm，流式计算，了解-Spark，S4"><a href="#Storm，流式计算，了解-Spark，S4" class="headerlink" title="Storm，流式计算，了解 Spark，S4"></a>Storm，流式计算，了解 Spark，S4</h5><p>在 linux 上部署 storm，用 zookeeper 做协调，运行 storm hello world，local 和 remote 模式运行调试 storm topology。</p>
<h5 id="Hadoop，离线计算"><a href="#Hadoop，离线计算" class="headerlink" title="Hadoop，离线计算"></a>Hadoop，离线计算</h5><p>HDFS、MapReduce</p>
<h5 id="分布式日志收集-flume，kafka，logstash"><a href="#分布式日志收集-flume，kafka，logstash" class="headerlink" title="分布式日志收集 flume，kafka，logstash"></a>分布式日志收集 flume，kafka，logstash</h5><h5 id="数据挖掘，mahout"><a href="#数据挖掘，mahout" class="headerlink" title="数据挖掘，mahout"></a>数据挖掘，mahout</h5><h4 id="网络安全知识"><a href="#网络安全知识" class="headerlink" title="网络安全知识"></a>网络安全知识</h4><h5 id="什么是-XSS"><a href="#什么是-XSS" class="headerlink" title="什么是 XSS"></a>什么是 XSS</h5><p>XSS 的防御</p>
<h5 id="什么是-CSRF"><a href="#什么是-CSRF" class="headerlink" title="什么是 CSRF"></a>什么是 CSRF</h5><h5 id="什么是注入攻击"><a href="#什么是注入攻击" class="headerlink" title="什么是注入攻击"></a>什么是注入攻击</h5><p>SQL 注入、XML 注入、CRLF 注入</p>
<h5 id="什么是文件上传漏洞"><a href="#什么是文件上传漏洞" class="headerlink" title="什么是文件上传漏洞"></a>什么是文件上传漏洞</h5><h5 id="加密与解密"><a href="#加密与解密" class="headerlink" title="加密与解密"></a>加密与解密</h5><p>MD5，SHA1、DES、AES、RSA、DSA</p>
<h5 id="什么是-DOS-攻击和-DDOS-攻击"><a href="#什么是-DOS-攻击和-DDOS-攻击" class="headerlink" title="什么是 DOS 攻击和 DDOS 攻击"></a>什么是 DOS 攻击和 DDOS 攻击</h5><p>memcached 为什么可以导致 DDos 攻击、什么是反射型 DDoS</p>
<h5 id="SSL、TLS，HTTPS"><a href="#SSL、TLS，HTTPS" class="headerlink" title="SSL、TLS，HTTPS"></a>SSL、TLS，HTTPS</h5><h5 id="如何通过-Hash-碰撞进行-DOS-攻击"><a href="#如何通过-Hash-碰撞进行-DOS-攻击" class="headerlink" title="如何通过 Hash 碰撞进行 DOS 攻击"></a>如何通过 Hash 碰撞进行 DOS 攻击</h5><h5 id="用-openssl-签一个证书部署到-apache-或-nginx"><a href="#用-openssl-签一个证书部署到-apache-或-nginx" class="headerlink" title="用 openssl 签一个证书部署到 apache 或 nginx"></a>用 openssl 签一个证书部署到 apache 或 nginx</h5><h3 id="四、架构篇"><a href="#四、架构篇" class="headerlink" title="四、架构篇"></a>四、架构篇</h3><h5 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h5><p>数据一致性、服务治理、服务降级</p>
<h5 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h5><p>2PC、3PC、CAP、BASE、 可靠消息最终一致性、最大努力通知、TCC</p>
<h5 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h5><p>服务注册、服务发现，服务治理</p>
<h5 id="分布式数据库"><a href="#分布式数据库" class="headerlink" title="分布式数据库"></a>分布式数据库</h5><p>怎样打造一个分布式数据库、什么时候需要分布式数据库、mycat、otter、HBase</p>
<h5 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h5><p>mfs、fastdfs</p>
<h5 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h5><p>缓存一致性、缓存命中率、缓存冗余</p>
<h4 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h4><p>SOA、康威定律</p>
<h5 id="ServiceMesh"><a href="#ServiceMesh" class="headerlink" title="ServiceMesh"></a>ServiceMesh</h5><h5 id="Docker-amp-Kubernets"><a href="#Docker-amp-Kubernets" class="headerlink" title="Docker &amp; Kubernets"></a>Docker &amp; Kubernets</h5><h5 id="Spring-Boot"><a href="#Spring-Boot" class="headerlink" title="Spring Boot"></a>Spring Boot</h5><h5 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h5><h4 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h4><h5 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h5><h5 id="分库分表-1"><a href="#分库分表-1" class="headerlink" title="分库分表"></a>分库分表</h5><h5 id="CDN-技术"><a href="#CDN-技术" class="headerlink" title="CDN 技术"></a>CDN 技术</h5><h5 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h5><p>ActiveMQ、RabbitMQ、Kafka</p>
<h4 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h4><h5 id="监控什么"><a href="#监控什么" class="headerlink" title="监控什么"></a>监控什么</h5><p>CPU、内存、磁盘 I/O、网络 I/O 等</p>
<h5 id="监控手段"><a href="#监控手段" class="headerlink" title="监控手段"></a>监控手段</h5><p>进程监控、语义监控、机器资源监控、数据波动</p>
<h5 id="监控数据采集"><a href="#监控数据采集" class="headerlink" title="监控数据采集"></a>监控数据采集</h5><p>日志、埋点</p>
<h5 id="Dapper"><a href="#Dapper" class="headerlink" title="Dapper"></a>Dapper</h5><h5 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h5><p>tomcat 负载均衡、Nginx 负载均衡</p>
<h5 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h5><p>DNS 原理、DNS 的设计</p>
<h5 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h5><h5 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h5><h3 id="五、-扩展篇"><a href="#五、-扩展篇" class="headerlink" title="五、 扩展篇"></a>五、 扩展篇</h3><h4 id="云计算"><a href="#云计算" class="headerlink" title="云计算"></a>云计算</h4><p>IaaS、SaaS、PaaS、虚拟化技术、openstack、Serverlsess</p>
<h5 id="搜索引擎"><a href="#搜索引擎" class="headerlink" title="搜索引擎"></a>搜索引擎</h5><p>Solr、Lucene、Nutch、Elasticsearch</p>
<h5 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h5><p>Shiro</p>
<h5 id="区块链"><a href="#区块链" class="headerlink" title="区块链"></a>区块链</h5><p>哈希算法、Merkle 树、公钥密码算法、共识算法、Raft 协议、Paxos 算法与 Raft 算法、拜占庭问题与算法、消息认证码与数字签名</p>
<h5 id="比特币"><a href="#比特币" class="headerlink" title="比特币"></a>比特币</h5><p>挖矿、共识机制、闪电网络、侧链、热点问题、分叉</p>
<h5 id="以太坊"><a href="#以太坊" class="headerlink" title="以太坊"></a>以太坊</h5><p>超级账本<br>人工智能<br>数学基础、机器学习、人工神经网络、深度学习、应用场景。</p>
<h5 id="常用框架"><a href="#常用框架" class="headerlink" title="常用框架"></a>常用框架</h5><p>TensorFlow、DeepLearning4J</p>
<h5 id="其他语言"><a href="#其他语言" class="headerlink" title="其他语言"></a>其他语言</h5><p>Groovy、Python、Go、NodeJs、Swift、Rust</p>
<h3 id="六、-推荐书籍"><a href="#六、-推荐书籍" class="headerlink" title="六、 推荐书籍"></a>六、 推荐书籍</h3><p>《深入理解 Java 虚拟机》 《 Effective Java 》 《深入分析 Java Web 技术内幕》 《大型网站技术架构》 《代码整洁之道》 《 Head First 设计模式》 《 maven 实战》 《区块链原理、设计与应用》 《 Java 并发编程实战》 《鸟哥的 Linux 私房菜》 《从 Paxos 到 Zookeeper 》 《架构即未来》</p>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2018/06/28/java 工程师成神之路(转载)/" data-id="ckbyfke19000izbyn8d0fzjqe" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    

                

</article>
        
    </article>
    
  
    
      <nav class="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next</a>
      </nav>
    
  </section>
</div>

  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-bar-chart"></i> <span id="busuanzi_value_site_pv"></span></li>
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 花谢花开</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="花谢花开"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>
<script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/ocean.js"></script>

</body>
</html>