<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  
  
    <meta name="description" content="人们常常嘲笑“螳臂当车” 但有时候啊，你并不是驾车的人 正巧是那只，反抗不了的螳螂。">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    centos搭建ELK集群 |
    
    花谢花开</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>
</html>
<body>
<main class="content">
  <section class="outer">
  <article id="post-elk集群搭建" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="article-title" itemprop="name">
      centos搭建ELK集群
    </h1>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2019/04/18/elk集群搭建/" class="article-date">
  <time datetime="2019-04-18T11:22:37.000Z" itemprop="datePublished">2019-04-18</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/elk/">elk</a>
  </div>

                    </div>
                    

                        
                            
    <div class="tocbot"></div>





                                

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h1 id="centos搭建ELK集群"><a href="#centos搭建ELK集群" class="headerlink" title=" centos搭建ELK集群"></a><center> centos搭建ELK集群</center></h1><blockquote>
<p>在之前两篇文章中我们详细讲述了如何在一台机器中搭建Filebeat + ELK单点服务，但是ELK服务若是上生产，为了实现高可用，我们需要搭建分布式集群。</p>
</blockquote>
<p>   集群架构图：<br>   <img src="https://res.cloudinary.com/leon824/image/upload/v1555588911/elk_xitdtn.png" alt><br>整个集群的部署是在下面这三台中的，机器ip<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.20.0.203</span><br><span class="line">172.30.0.199</span><br><span class="line">172.17.71.113</span><br></pre></td></tr></table></figure></p>
<p>根据个人这些年搭建各种集群的经验来说，想要快速完成集群搭建，我们一定要注意控制<strong>”变量“</strong>，也就是说我们完成一个模块的配置之后要快速验证当前这一个模块是否配置正常，不要着急去配置后边的模块，若是出现问题，这样可能会导致后边难以定位具体问题出现在哪里，白白浪费时间，切记切记。</p>
<h3 id="集群配置免密登录"><a href="#集群配置免密登录" class="headerlink" title="集群配置免密登录"></a>集群配置免密登录</h3><h5 id="1、先在各个环境中生成秘钥对。"><a href="#1、先在各个环境中生成秘钥对。" class="headerlink" title="1、先在各个环境中生成秘钥对。"></a>1、先在各个环境中生成秘钥对。</h5><p>下面的指令需要在各个环境中执行，生成对应的公私钥</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<h5 id="2、-将各个环境中的公钥全部集中到一个authorized-keys文件中"><a href="#2、-将各个环境中的公钥全部集中到一个authorized-keys文件中" class="headerlink" title="2、 将各个环境中的公钥全部集中到一个authorized_keys文件中"></a>2、 将各个环境中的公钥全部集中到一个<code>authorized_keys</code>文件中</h5><h5 id="3、然后将这个文件分发到各个机器的-ssh目录下面。"><a href="#3、然后将这个文件分发到各个机器的-ssh目录下面。" class="headerlink" title="3、然后将这个文件分发到各个机器的.ssh目录下面。"></a>3、然后将这个文件分发到各个机器的.ssh目录下面。</h5><p>上述操作步骤并不复杂，但是在实际操作中需要注意一些地方，下面举例需要特别注意的地方。</p>
<h5 id="可能会出现的问题-："><a href="#可能会出现的问题-：" class="headerlink" title="可能会出现的问题 ："></a>可能会出现的问题 ：</h5><p>a，不要忘记修改sshd服务的配置。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes</span><br><span class="line">PubkeyAuthentication yes</span><br><span class="line">AuthorizedKeysFile      /home/felk/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></p>
<p>然后重启sshd服务<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sudo service sshd restart</span><br></pre></td></tr></table></figure></p>
<p>特别是最后一个配置涉及到<code>authorized_keys</code>文件的目录，需要根据自己的实际配置目录添加进去。</p>
<p>b、<code>ssh_exchange_identification: Connection closed by remote host</code>报错</p>
<p>解决办法：<br>先登录到需要目标机器中查看 <code>/etc/hosts.allow</code>文件中是否允许响应网段ip访问。修改之后重启sshd服务。</p>
<p>主要就是上边的两个问题。</p>
<h3 id="配置zookeeper集群"><a href="#配置zookeeper集群" class="headerlink" title="配置zookeeper集群"></a>配置zookeeper集群</h3><p>由于我们的架构中使用到了kafka，kafka集群是需要zookeeper集群来管理的，所以在安装kafka之前需要安装zk集群。</p>
<p>1、先在三台机器中zk目录的根目录下分别创两个目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir logs</span><br><span class="line">$ mkdir data</span><br></pre></td></tr></table></figure>
<p>2、然后分别在data目录中创建一个<code>myid</code>文件，这个文件里边只有一个数字，代表当前zk服务的标记，三个zookeeper模块中的myid文件中的内容必须保证不同。<br>3、进入zk的conf目录，创建一个名为zoo.cfg的文件，填入以下内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/opt/soft/zookeeper/data</span><br><span class="line">dataLogDir=/opt/soft/zookeeper/logs</span><br><span class="line">clientPort=2181</span><br><span class="line">server.0=172.20.0.203:2888:3888</span><br><span class="line">server.1=172.30.0.199:2888:3888</span><br><span class="line">server.2=172.17.71.113:2888:3888</span><br></pre></td></tr></table></figure>
<p>需要注意最后三行配置，server.0、server.1、server.2中的0、1、2就是之前你创建myid文件中写入的值。</p>
<p>然后将文件分发到各个服务器中。</p>
<p>为了方便使用，我们可以在配置文件中加入zookeeper的环境变量。</p>
<p>然后在三台机器中分别执行<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> zkServer.sh start</span><br></pre></td></tr></table></figure></p>
<p>启动完成后分别执行<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[felk@blv0104 conf]$ zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/soft/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line">[felk@blv0114 conf]$ zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/soft/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line"></span><br><span class="line">[felk@blv0115 es]$ zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/soft/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure></p>
<p>若出现上面的的信息，则说明配置正确。</p>
<h3 id="配置kafka集群"><a href="#配置kafka集群" class="headerlink" title="配置kafka集群"></a>配置kafka集群</h3><p>1、分别进入kakfa的目录，在根目录下面创建一个<code>logs</code>的目录。</p>
<p>2、进入<code>config</code>目录，编辑<code>server.properties</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> kafka-1</span><br><span class="line"><span class="meta">#</span>注意和集群中其他机器不同</span><br><span class="line">broker.id=0     </span><br><span class="line">listeners=PLAINTEXT://172.20.0.203:9092</span><br><span class="line"><span class="meta"> #</span>当前机器的ip</span><br><span class="line">advertised.host.name=172.20.0.203  </span><br><span class="line">num.network.threads=3</span><br><span class="line">num.io.threads=8</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">log.dirs=/opt/soft/kafka/logs</span><br><span class="line">num.partitions=1</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line">log.retention.hours=168</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line">delete.topic.enable=true</span><br><span class="line">auto.create.topics.enable=false</span><br><span class="line">zookeeper.connect=172.20.0.203:2181,172.30.0.199:2181,172.17.71.113:2181</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> kafka-2</span><br><span class="line"><span class="meta">#</span>注意和集群中其他机器不同</span><br><span class="line">broker.id=1   </span><br><span class="line">listeners=PLAINTEXT://172.30.0.199:9092</span><br><span class="line"><span class="meta">#</span>当前机器的ip</span><br><span class="line">advertised.host.name=172.30.0.199 </span><br><span class="line">num.network.threads=3</span><br><span class="line">num.io.threads=8</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">log.dirs=/opt/soft/kafka/logs</span><br><span class="line">num.partitions=1</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line">log.retention.hours=168</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line">delete.topic.enable=true</span><br><span class="line">auto.create.topics.enable=false</span><br><span class="line">zookeeper.connect=172.20.0.203:2181,172.30.0.199:2181,172.17.71.113:2181</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> kafka-3</span><br><span class="line"><span class="meta">#</span>注意和集群中其他机器不同</span><br><span class="line">broker.id=2   </span><br><span class="line">listeners=PLAINTEXT://172.17.71.113:9092</span><br><span class="line"><span class="meta">#</span>当前机器的ip</span><br><span class="line">advertised.host.name=172.17.71.113 </span><br><span class="line">num.network.threads=3</span><br><span class="line">num.io.threads=8</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">log.dirs=/opt/soft/kafka/logs</span><br><span class="line">num.partitions=1</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line">log.retention.hours=168</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line">delete.topic.enable=true</span><br><span class="line">auto.create.topics.enable=false</span><br><span class="line">zookeeper.connect=172.20.0.203:2181,172.30.0.199:2181,172.17.71.113:2181</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure>
<p>上边配置完成后分别在各个机器上启动。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure>
<p>然后看看进程有没有启动成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[felk@blv0104 kafka]$ jps</span><br><span class="line">4740 Kafka</span><br><span class="line">6806 QuorumPeerMain</span><br><span class="line">16936 Main</span><br><span class="line">2750 ConsoleConsumer</span><br></pre></td></tr></table></figure>
<p>为了验证集群是否配置成功，我们可以开启一个生产者，然后在其他机器开启消费者，若是都能正常消费生产者发出的消息，那么可以证明此时集群是运行正常的。</p>
<h3 id="配置logstash集群"><a href="#配置logstash集群" class="headerlink" title="配置logstash集群"></a>配置logstash集群</h3><p>logstash配置是整个集群最麻烦的一个模块，涉及到改动比较多，我们解析nginx日志此时不在用正则去解析匹配了，而是先将nginx format的格式，用‘|’来间隔，这样就能直接使用ruby的spite方法将各个字段解析出来。</p>
<p>基于之前的单点配置，这里集群的配置并不需要改动多少配置，只需要将<code>logstash.conf</code>文件的input、output模块修改，主要是在各台机器上修改下面的内容<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">input&#123;</span><br><span class="line">    kafka&#123;</span><br><span class="line">       topics =&gt; ["nginx_log"] </span><br><span class="line">       add_field =&gt; &#123;"myid"=&gt;"nginx_log_input"&#125;</span><br><span class="line">       bootstrap_servers =&gt; "172.20.0.203:9092,172.30.0.199:9092,172.17.71.113:9092"</span><br><span class="line">       codec =&gt; "json"</span><br><span class="line">    &#125;</span><br><span class="line">    kafka&#123;</span><br><span class="line">       topics =&gt; ["bling-service-tps"] </span><br><span class="line">       add_field =&gt; &#123;"myid"=&gt;"bling-service-tps"&#125;</span><br><span class="line">       bootstrap_servers =&gt; "172.20.0.203:9092,172.30.0.199:9092,172.17.71.113:9092"</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">   if [myid] == "nginx_log_input" &#123; </span><br><span class="line">    ruby &#123;</span><br><span class="line">            init =&gt; "@kname = ['remote_addr','time_local','host','request','status','body_bytes_sent','http_referer','http_x_forwarded_for','http_user_agent','request_time','upstream_response_time']"</span><br><span class="line">            code =&gt; "</span><br><span class="line">                new_event = LogStash::Event.new(Hash[@kname.zip(event.get('message').split('|'))])</span><br><span class="line">                new_event.remove('@timestamp')</span><br><span class="line">                event.append(new_event)</span><br><span class="line">            "</span><br><span class="line">    &#125;</span><br><span class="line">    if [request] &#123;</span><br><span class="line">        ruby &#123;</span><br><span class="line">            init =&gt; "@kname = ['method','uri']"</span><br><span class="line">            code =&gt; "</span><br><span class="line">                new_event = LogStash::Event.new(Hash[@kname.zip(event.get('request').split(' '))]) </span><br><span class="line">                new_event.remove('@timestamp')</span><br><span class="line">                event.append(new_event)</span><br><span class="line">            "</span><br><span class="line">    &#125;</span><br><span class="line">    if [uri] &#123;</span><br><span class="line">        ruby &#123;</span><br><span class="line">            init =&gt; "@kname = ['url_path','url_args']"</span><br><span class="line">            code =&gt; "</span><br><span class="line">                new_event = LogStash::Event.new(Hash[@kname.zip(event.get('uri').split('?'))])</span><br><span class="line">                new_event.remove('@timestamp')</span><br><span class="line">                new_event.remove('url_args')</span><br><span class="line">                event.append(new_event)</span><br><span class="line">            "</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   if [url_path] &#123;</span><br><span class="line">            ruby &#123;</span><br><span class="line">                init =&gt; "@kname = ['service_name', 'module_name']"</span><br><span class="line">                code =&gt; "</span><br><span class="line">                    new_event = LogStash::Event.new(Hash[@kname.zip(event.get('uri').split('/'))])</span><br><span class="line">                    new_event.remove('service_name')</span><br><span class="line">                    new_event.remove('@timestamp')</span><br><span class="line">                    event.append(new_event)</span><br><span class="line">                "</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mutate&#123;</span><br><span class="line">           convert =&gt; ["request_time", "float"]</span><br><span class="line">           convert =&gt; ["status", "integer"]</span><br><span class="line">           convert =&gt; ["body_bytes_sent", "float"]</span><br><span class="line">           convert =&gt; ["upstream_response_time", "float"]</span><br><span class="line">    &#125;</span><br><span class="line">    if [module_name] == "monitor" or [module_name] == "weixin" or [method] == "OPTIONS" &#123;</span><br><span class="line">            drop &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">    if [myid] == "nginx_log_input" &#123;</span><br><span class="line">        elasticsearch&#123;</span><br><span class="line">        hosts =&gt; ["172.20.0.203:9200", "172.30.0.199:9200", "172.17.71.113:9200"]</span><br><span class="line">        index =&gt; "nginx-log"</span><br><span class="line">        template_overwrite =&gt; true</span><br><span class="line">        template =&gt; "/opt/soft/logstash/output/es_template.json"</span><br><span class="line">        &#125;</span><br><span class="line">        stdout&#123;codec =&gt; rubydebug&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if [myid] == "bling-service-tps" &#123;</span><br><span class="line">        elasticsearch&#123;</span><br><span class="line">            hosts =&gt; ["172.20.0.203:9200", "172.30.0.199:9200", "172.17.71.113:9200"]</span><br><span class="line">            index =&gt; "bling-service-tps"</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>中间的filter模块不动改动。</p>
<h3 id="配置es集群"><a href="#配置es集群" class="headerlink" title="配置es集群"></a>配置es集群</h3><p>1、还是分别在es的根目录下边分别创建logs、data目录<br>2、然后进入<code>config</code>目录中编辑elasticsearch.yml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> es-1</span><br><span class="line">cluster.name: BlingABC_ES-Cluster </span><br><span class="line">path.data: /opt/soft/elasticsearch-5.6.14/data</span><br><span class="line">path.logs: /opt/soft/elasticsearch-5.6.14/logs</span><br><span class="line">node.name: BlingABC_ES1 </span><br><span class="line">node.data: true</span><br><span class="line">node.master: true</span><br><span class="line">network.host: 172.20.0.203</span><br><span class="line">http.port: 9200</span><br><span class="line">discovery.zen.ping.unicast.hosts: ["172.20.0.203", "172.30.0.199", "172.17.71.113"]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: "*"</span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>es-2</span><br><span class="line">cluster.name: BlingABC_ES-Cluster </span><br><span class="line">path.data: /opt/soft/elasticsearch-5.6.14/data</span><br><span class="line">path.logs: /opt/soft/elasticsearch-5.6.14/logs</span><br><span class="line">node.name: BlingABC_ES2 </span><br><span class="line">node.data: true</span><br><span class="line">node.master: true</span><br><span class="line">network.host: 172.30.0.199 </span><br><span class="line">http.port: 9200</span><br><span class="line">discovery.zen.ping.unicast.hosts: ["172.20.0.203", "172.30.0.199", "172.17.71.113"]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: "*"</span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>es-3</span><br><span class="line">cluster.name: BlingABC_ES-Cluster </span><br><span class="line">path.data: /opt/soft/elasticsearch-5.6.14/data</span><br><span class="line">path.logs: /opt/soft/elasticsearch-5.6.14/logs</span><br><span class="line">node.name: BlingABC_ES3 </span><br><span class="line">node.data: true</span><br><span class="line">node.master: true</span><br><span class="line">network.host: 172.17.71.113 </span><br><span class="line">http.port: 9200</span><br><span class="line">discovery.zen.ping.unicast.hosts: ["172.20.0.203", "172.30.0.199", "172.17.71.113"]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: "*"</span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br></pre></td></tr></table></figure>
<p>上边需要注意的几个配置:</p>
<p><code>cluster.name</code>：三台机器中这个字段值都是一致的，表示这个集群的名称。<br><code>node.name</code>:各个节点的名称，三台机器中这个值都是不同的。<br><code>discovery.zen.ping.unicast.hosts</code>:es集群相互通信的主机ip，若是不填端口，默认是<code>9092</code>端口。<br><code>discovery.zen.minimum_master_nodes</code>：这个值推荐是节点数 n/2+1 </p>
<p>3、分别启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./bin/elasticsearch &amp;</span><br></pre></td></tr></table></figure></p>
<p>4、我们在第三步已经将es集群启动了，但是我们应该检查一下当前es集群状态是否成功。我们需要借助一个插件<code>elasticsearch-head</code>，</p>
<p>这里我们就不记录这个插件的安装启动了。启动之后我们访问9100端口，若能看到下面的内容，说明此时集群状态正常。</p>
<p><img src="media/15548098580919.jpg" alt></p>
<h4 id="定期删除es中的数据"><a href="#定期删除es中的数据" class="headerlink" title="定期删除es中的数据"></a>定期删除es中的数据</h4><p>我们的es集群中若是不设置定期删除索引，es本身是不会主动删除之前索引的，为了减少存储量、加快查询速度，我们可以使用es自带的删除工具<code>_delete_by_query</code>可以很简单的实现定期删除指定时间之前的数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curl -H 'Content-Type:application/json' -d'&#123;</span><br><span class="line">    "query": &#123;</span><br><span class="line">        "range": &#123;</span><br><span class="line">            "@timestamp": &#123;</span><br><span class="line">                "lt": "now-7d",</span><br><span class="line">                "format": "epoch_millis"</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;' -XPOST "http://172.17.71.113:9200/*-*/_delete_by_query?pretty"</span><br></pre></td></tr></table></figure>
<p>以上的语句就可以将当前集群中7天以前的数据删除。然后我们可以考虑创建一个定时任务来执行清理任务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* 0 * * * /usr/bin/curl -u username:password  -H&apos;Content-Type:application/json&apos; -d&apos;&#123;&quot;query&quot;:&#123;&quot;range&quot;:&#123;&quot;@timestamp&quot;:&#123;&quot;lt&quot;:&quot;now-7d&quot;,&quot;format&quot;:&quot;epoch_millis&quot;&#125;&#125;&#125;&#125;&apos; -XPOST &quot;http://127.0.0.1:9200/*-*/_delete_by_query?pretty&quot; &gt; /tmp/elk_clean.txt</span><br></pre></td></tr></table></figure>
<p>每天0点删除超过7天的无效索引</p>
<h3 id="配置kibana集群"><a href="#配置kibana集群" class="headerlink" title="配置kibana集群"></a>配置kibana集群</h3><p>在这个集群中，kibana负责为用户提供页面展示，我们在三台机器中分别部署kibana服务，然后前面加上nginx的反向代理来将用户请求分散到三台机器中。</p>
<p>kibana的配置非常简单</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kibana-1</span><br><span class="line">server.port: 5601</span><br><span class="line">server.host: "172.20.0.203"</span><br><span class="line">server.name: "BlingABC_Kibana"</span><br><span class="line">elasticsearch.url: "http://172.20.0.203:9200"</span><br><span class="line"></span><br><span class="line">kibana-2</span><br><span class="line">server.port: 5601</span><br><span class="line">server.host: "172.30.0.199"</span><br><span class="line">server.name: "BlingABC_Kibana"</span><br><span class="line">elasticsearch.url: "http://172.30.0.199:9200"</span><br><span class="line"></span><br><span class="line">kibana-3</span><br><span class="line">server.port: 5601</span><br><span class="line">server.host: "172.17.71.113"</span><br><span class="line">server.name: "BlingABC_Kibana"</span><br><span class="line">elasticsearch.url: "http://172.17.71.113:9200"</span><br></pre></td></tr></table></figure>
<p>分别启动<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kibana &amp;</span><br></pre></td></tr></table></figure></p>
<p>接下来可以直接通过ip访问具体服务了</p>
<p>比如我们访问<code>http://172.17.71.113:5601</code>可以看到如下页面（这里是已经创建好索引的）</p>
<p><img src="media/15548099030473.jpg" alt></p>
<h3 id="安装Grafana"><a href="#安装Grafana" class="headerlink" title="安装Grafana"></a>安装Grafana</h3><p>先去官网下载对应操作系统的Grafana安装源</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sudo yum localinstall grafana-6.0.2-1.x86_64.rpm</span><br></pre></td></tr></table></figure>
<p>启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup sudo service grafana-server start &amp;</span><br></pre></td></tr></table></figure></p>
<p>查看状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo service grafana-server status</span><br></pre></td></tr></table></figure></p>
<p>我们可以在/etc/grafana/grafana.ini中自定义一些grafana的一些参数。</p>
<hr>
<h3 id="备注：集群启动指令"><a href="#备注：集群启动指令" class="headerlink" title="备注：集群启动指令"></a>备注：集群启动指令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// 启动zookeeper</span><br><span class="line"><span class="meta">$</span> nohup bin/zookeeper-server-start.sh -daemon config/zookeeper.properties &amp;</span><br><span class="line">// 启动kafka</span><br><span class="line"><span class="meta">$</span> nohup bin/kafka-server-start.sh config/server.properties &amp;</span><br><span class="line">// 启动logstash</span><br><span class="line"><span class="meta">$</span> nohup ./bin/logstash -f config/logstash.conf &amp; </span><br><span class="line">// 启动es</span><br><span class="line"><span class="meta">$</span> nohup ./bin/elasticsearch &amp;</span><br><span class="line">// 启动es插件</span><br><span class="line"><span class="meta">$</span> nohup npm run start &amp;</span><br><span class="line">// 启动kibana</span><br><span class="line"><span class="meta">$</span> nohup ./bin/kibana &amp;</span><br><span class="line">// 启动grafana</span><br><span class="line"><span class="meta">$</span> nohup sudo service grafana-server start &amp;</span><br><span class="line">// 查看grafana状态</span><br><span class="line"><span class="meta">$</span> sudo service grafana-server status</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="kafka的一些操作"><a href="#kafka的一些操作" class="headerlink" title="kafka的一些操作"></a>kafka的一些操作</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 查看当前kafka集群的topic</span><br><span class="line"><span class="meta">$</span> bin/kafka-topics.sh --list --zookeeper 172.20.0.203:2181,172.30.0.199:2181,172.17.71.113:2181</span><br><span class="line">// 查看nginx_log主题的信息</span><br><span class="line"><span class="meta">$</span> bin/kafka-console-consumer.sh --zookeeper 172.20.0.203:2181,172.30.0.199:2181,172.17.71.113:2181 --topic nginx_log</span><br><span class="line"><span class="meta">$</span> 创建主题</span><br><span class="line"><span class="meta">$</span> bin/kafka-topics.sh --create --zookeeper 172.20.0.203:2181,172.30.0.199:2181,172.17.71.113:2181 --replication-factor 1 --partitions 1 --topic bling-service-general</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html" target="_blank" rel="noopener">Elasticsearch Reference </a><br><a href="https://juejin.im/post/58e5de06ac502e006c254145" target="_blank" rel="noopener">elasticsearch按照日期定时批量删除索引</a><br><a href="https://blog.csdn.net/piantoutongyang/article/details/88811840" target="_blank" rel="noopener">偏头痛杨的分布式日志框架ELK入门helloworld</a></p>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2019/04/18/elk集群搭建/" data-id="ckbyfke0f0006zbyn44fx68rf" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    
        
  <nav class="article-nav">
    
      <a href="/2020/07/07/浅谈计算机领域的缓存/" class="article-nav-link">
        <strong class="article-nav-caption">Newer</strong>
        <div class="article-nav-title">
          
            浅谈计算机领域的缓存
          
        </div>
      </a>
    
    
      <a href="/2019/02/18/历史的逻辑/" class="article-nav-link">
        <strong class="article-nav-caption">Older</strong>
        <div class="article-nav-title">历史的逻辑</div>
      </a>
    
  </nav>


            

                
                    
                        
                            

</article>
</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 花谢花开</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="花谢花开"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>
<script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/tocbot.min.js"></script>
  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script src="/js/ocean.js"></script>

</body>
</html>