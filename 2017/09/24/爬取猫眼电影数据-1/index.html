<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  
  
    <meta name="description" content="人们常常嘲笑“螳臂当车” 但有时候啊，你并不是驾车的人 正巧是那只，反抗不了的螳螂。">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    爬取猫眼电影数据（一） |
    
    花谢花开</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>
</html>
<body>
<main class="content">
  <section class="outer">
  <article id="post-爬取猫眼电影数据-1" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="article-title" itemprop="name">
      爬取猫眼电影数据（一）
    </h1>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2017/09/24/爬取猫眼电影数据-1/" class="article-date">
  <time datetime="2017-09-24T14:40:16.000Z" itemprop="datePublished">2017-09-24</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>

                    </div>
                    

                        
                            
    <div class="tocbot"></div>





                                

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <h1 id="爬取猫眼电影数据-一"><a href="#爬取猫眼电影数据-一" class="headerlink" title="爬取猫眼电影数据(一)"></a>爬取猫眼电影数据(一)</h1><blockquote>
<p>概述：近期由于业务需要，需要将爬取猫眼网站中的部分数据作为公众号数据源，猫眼的电影数据相当之全备，大概收录了几十万部电影。当然这些数据我们也没那么容易就能爬取到的。遂将整个爬取过程记录如下。</p>
</blockquote>
<p>1、使用chrome进入开发者模式，观察html结构、元素，找到我们所需数据，第一步我们需要现获取每一个电影的详情页面url。</p>
<p> <img src="http://res.cloudinary.com/leon824/image/upload/v1506261484/1_b4qehh.png" width="100%" height="100%"></p>
<blockquote>
<p><strong>注意，在爬取猫眼的电影数据时并不需要登录和携带cookie去请求html</strong></p>
</blockquote>
<p>2、 这里我们结合BeautifulSoup和xpath来实现对数据的过滤。实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_detail_url</span><span class="params">(self, targetUrl)</span>:</span></span><br><span class="line">    <span class="string">"""从概览页面中去获取剧透影片的详情页面"""</span></span><br><span class="line">    html = self.getHtml(targetUrl) </span><br><span class="line">    <span class="keyword">print</span> html</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    urls = soup.find_all(<span class="string">'a'</span>, attrs=&#123;<span class="string">'data-act'</span>:<span class="string">'movie-click'</span>&#125;)</span><br><span class="line">    dd = soup.find_all(<span class="string">'dd'</span>) </span><br><span class="line">    <span class="keyword">print</span> dd</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        detailPath = etree.HTML(str(url))</span><br><span class="line">        detail_url = detailPath.xpath(<span class="string">r'//a/@href'</span>)</span><br><span class="line">        <span class="keyword">for</span> durl <span class="keyword">in</span> detail_url:</span><br><span class="line">            self.getContents(<span class="string">'https://maoyan.com'</span> + durl, proxys)</span><br></pre></td></tr></table></figure>
<p>然后获取到对应每一个电影的详情url，进入详情页，分析所需数据对应html元素。在这里我们只需要三个字段、电影名称、电影海报url、电影上映时间。</p>
<p><img src="http://res.cloudinary.com/leon824/image/upload/v1506262397/3_yrxyxr.png" width="100%" height="100%"></p>
<blockquote>
<p>提示:<em>使用xpath时，最简单的方式是在chrome中点击选中具体某一个元素，然后右键——&gt; copy –&gt; copy xpath就能获取到对应的xpath路径</em><br><img src="http://res.cloudinary.com/leon824/image/upload/v1506263006/4_bsgqfg.png" width="100%" height="100%"></p>
</blockquote>
<p>实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getContents</span><span class="params">(self, url, proxys)</span>:</span></span><br><span class="line">        <span class="string">"""从详情页面中获取所需data"""</span></span><br><span class="line">        html  = self.getHtml(url,proxys)</span><br><span class="line">        detailPath = etree.HTML(html)</span><br><span class="line">        <span class="comment">#电影名称</span></span><br><span class="line">        film_name = detailPath.xpath(<span class="string">r'/html/body/div[3]/div/div[2]/div[1]/h3/text()'</span>) </span><br><span class="line">			<span class="comment">#图片url</span></span><br><span class="line">        pic_url = detailPath.xpath(<span class="string">r'/html/body/div[3]/div/div[1]/div/img/@src'</span>)</span><br><span class="line">         <span class="comment">#上映时间   </span></span><br><span class="line">        release_time = detailPath.xpath(<span class="string">r'/html/body/div[3]/div/div[2]/div[1]/ul/li[3]/text()'</span>)</span><br></pre></td></tr></table></figure>
<p>3、 这个时候获取到数据了，就该存库了。嗯，就存到mysql中吧。没啥说的，上代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertData</span><span class="params">(self, my_dict)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.db.set_character_set(<span class="string">'utf8'</span>)</span><br><span class="line">            cols = <span class="string">', '</span>.join(my_dict.keys())</span><br><span class="line">            <span class="keyword">print</span> cols</span><br><span class="line">            values = <span class="string">'","'</span>.join(my_dict.values())</span><br><span class="line">            <span class="keyword">print</span> values</span><br><span class="line">            sql = <span class="string">"INSERT INTO  maoyan (%s) VALUES (%s)"</span> % (cols, <span class="string">'"'</span> + values + <span class="string">'"'</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                result = self.cur.execute(sql)</span><br><span class="line">                insert_id = self.db.insert_id()</span><br><span class="line">                self.db.commit()</span><br><span class="line">                <span class="comment"># 判断是否执行成功</span></span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    <span class="keyword">return</span> insert_id</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">except</span> MySQLdb.Error, e:</span><br><span class="line">                <span class="comment"># 发生错误时回滚</span></span><br><span class="line">                self.db.rollback()</span><br><span class="line">                <span class="comment"># 主键唯一，无法插入</span></span><br><span class="line">                <span class="keyword">if</span> <span class="string">"key 'PRIMARY'"</span> <span class="keyword">in</span> e.args[<span class="number">1</span>]:</span><br><span class="line">                    <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"数据已存在，未插入数据"</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"插入数据失败，原因 %d: %s"</span> % (e.args[<span class="number">0</span>], e.args[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">except</span> MySQLdb.Error, e:</span><br><span class="line">            <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"数据库错误，原因%d: %s"</span> % (e.args[<span class="number">0</span>], e.args[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dealData</span><span class="params">(self, my_dict)</span>:</span></span><br><span class="line">        <span class="string">"""先从数据库中查询这个影片名的记录，如果没有直接插入；</span></span><br><span class="line"><span class="string">        若是数据库中已经存在数据，那么什么都不做"""</span></span><br><span class="line">        self.db.set_character_set(<span class="string">'utf8'</span>)</span><br><span class="line">        filmTitile = my_dict.get(<span class="string">'film_title'</span>)</span><br><span class="line">        result = self.findFilmByfilmTitle(filmTitile)</span><br><span class="line">        <span class="keyword">if</span> len(result) == <span class="number">0</span>:</span><br><span class="line">            self.insertData(my_dict)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findFilmByfilmTitle</span><span class="params">(self, filmTitile)</span>:</span></span><br><span class="line">        <span class="string">"""通过影片名称去数据库中查询"""</span></span><br><span class="line">        self.db.set_character_set(<span class="string">'utf8'</span>)</span><br><span class="line">        sql = <span class="string">"select * from maoyan where film_title='%s'"</span> % (filmTitile)</span><br><span class="line">        self.cur.execute(sql)</span><br><span class="line">        results = self.cur.fetchall()</span><br><span class="line">        self.db.commit()</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<p>4、 万事俱备只欠启动了，跑啊跑啊。想必大家都想到了，猫眼肯定是不可能随便让人这样爬取他们的数据，而且短时间大量的请求对服务器的负载也是相当大的，不出意料爬取了不到300条数据，就被停止了。(ಥ _ ಥ)<br>处理这种情况一般有两种方式，一种通过延缓请求，一种是通过代理ip的方式。第一种我尝试延缓5、10s，但并没有用。因而尝试用第二种方式，代理ip池的方式。<strong>代理ip如何使用在下一篇文章中记录。</strong></p>
<p>下面是本次的完成代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">"""猫眼不需要http请求的头部信息，添加上反而会出错"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Maoyan</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 获取当前时间</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getCurrentTime</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> time.strftime(<span class="string">'[%Y-%m-%d %H:%M:%S]'</span>, time.localtime(time.time()))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.time = time</span><br><span class="line">        self.base_url = <span class="string">"https://maoyan.com/films?showType=1&amp;sortId=2"</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.db = MySQLdb.connect(<span class="string">'localhost'</span>, <span class="string">'flyer_user'</span>, <span class="string">'Tu4a0X9hOPKz6jS!e'</span>, <span class="string">'flyer_db'</span>,charset=<span class="string">'utf8'</span>)</span><br><span class="line">            self.cur = self.db.cursor()</span><br><span class="line">        <span class="keyword">except</span> MySQLdb.Error, e:</span><br><span class="line">            <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"连接数据库错误，原因%d: %s"</span> % (e.args[<span class="number">0</span>], e.args[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 插入数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertData</span><span class="params">(self, my_dict)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.db.set_character_set(<span class="string">'utf8'</span>)</span><br><span class="line">            cols = <span class="string">', '</span>.join(my_dict.keys())</span><br><span class="line">            <span class="keyword">print</span> cols</span><br><span class="line">            values = <span class="string">'","'</span>.join(my_dict.values())</span><br><span class="line">            <span class="keyword">print</span> values</span><br><span class="line">            sql = <span class="string">"INSERT INTO  maoyan (%s) VALUES (%s)"</span> % (cols, <span class="string">'"'</span> + values + <span class="string">'"'</span>)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                result = self.cur.execute(sql)</span><br><span class="line">                insert_id = self.db.insert_id()</span><br><span class="line">                self.db.commit()</span><br><span class="line">                <span class="comment"># 判断是否执行成功</span></span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    <span class="keyword">return</span> insert_id</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">except</span> MySQLdb.Error, e:</span><br><span class="line">                <span class="comment"># 发生错误时回滚</span></span><br><span class="line">                self.db.rollback()</span><br><span class="line">                <span class="comment"># 主键唯一，无法插入</span></span><br><span class="line">                <span class="keyword">if</span> <span class="string">"key 'PRIMARY'"</span> <span class="keyword">in</span> e.args[<span class="number">1</span>]:</span><br><span class="line">                    <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"数据已存在，未插入数据"</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"插入数据失败，原因 %d: %s"</span> % (e.args[<span class="number">0</span>], e.args[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">except</span> MySQLdb.Error, e:</span><br><span class="line">            <span class="keyword">print</span> self.getCurrentTime(), <span class="string">"数据库错误，原因%d: %s"</span> % (e.args[<span class="number">0</span>], e.args[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dealData</span><span class="params">(self, my_dict)</span>:</span></span><br><span class="line">        <span class="string">"""先从数据库中查询这个影片名的记录，如果没有直接插入；</span></span><br><span class="line"><span class="string">        若是数据库中已经存在数据，那么什么都不做"""</span></span><br><span class="line">        self.db.set_character_set(<span class="string">'utf8'</span>)</span><br><span class="line">        filmTitile = my_dict.get(<span class="string">'film_title'</span>)</span><br><span class="line">        result = self.findFilmByfilmTitle(filmTitile)</span><br><span class="line">        <span class="keyword">if</span> len(result) == <span class="number">0</span>:</span><br><span class="line">            self.insertData(my_dict)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findFilmByfilmTitle</span><span class="params">(self, filmTitile)</span>:</span></span><br><span class="line">        <span class="string">"""通过影片名称去数据库中查询"""</span></span><br><span class="line">        self.db.set_character_set(<span class="string">'utf8'</span>)</span><br><span class="line">        sql = <span class="string">"select * from maoyan where film_title='%s'"</span> % (filmTitile)</span><br><span class="line">        self.cur.execute(sql)</span><br><span class="line">        results = self.cur.fetchall()</span><br><span class="line">        self.db.commit()</span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHtml</span><span class="params">(self,url,proxys)</span>:</span></span><br><span class="line">        <span class="string">"""获取html"""</span></span><br><span class="line">        req = urllib2.Request(url)</span><br><span class="line">        html = urllib2.urlopen(req).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_detail_url</span><span class="params">(self, targetUrl, proxys)</span>:</span></span><br><span class="line">        <span class="string">"""从概览页面中去获取剧透影片的详情页面"""</span></span><br><span class="line">        html = self.getHtml(targetUrl, proxys)</span><br><span class="line">        <span class="keyword">print</span> html</span><br><span class="line">        soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">        urls = soup.find_all(<span class="string">'a'</span>, attrs=&#123;<span class="string">'data-act'</span>:<span class="string">'movie-click'</span>&#125;)</span><br><span class="line">        dd = soup.find_all(<span class="string">'dd'</span>)</span><br><span class="line">        <span class="keyword">print</span> dd</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            detailPath = etree.HTML(str(url))</span><br><span class="line">            detail_url = detailPath.xpath(<span class="string">r'//a/@href'</span>)</span><br><span class="line">            <span class="keyword">for</span> durl <span class="keyword">in</span> detail_url:</span><br><span class="line">                self.getContents(<span class="string">'https://maoyan.com'</span> + durl, proxys)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getContents</span><span class="params">(self, url, proxys)</span>:</span></span><br><span class="line">        <span class="string">"""从详情页面中获取所需data"""</span></span><br><span class="line">        tmp1 = []</span><br><span class="line">        tmp2 = []</span><br><span class="line">        html  = self.getHtml(url,proxys)</span><br><span class="line">        detailPath = etree.HTML(html)</span><br><span class="line">        film_name = detailPath.xpath(<span class="string">r'/html/body/div[3]/div/div[2]/div[1]/h3/text()'</span>)</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> film_name:</span><br><span class="line">            tmp1.append(<span class="string">"film_title"</span>)</span><br><span class="line">            tmp2.append(name)</span><br><span class="line"></span><br><span class="line">        pic_url = detailPath.xpath(<span class="string">r'/html/body/div[3]/div/div[1]/div/img/@src'</span>)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> pic_url:</span><br><span class="line">            strs = url.split(<span class="string">'@'</span>)</span><br><span class="line">            tmp1.append(<span class="string">"pic_url"</span>)</span><br><span class="line">            tmp2.append(strs[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        release_time = detailPath.xpath(<span class="string">r'/html/body/div[3]/div/div[2]/div[1]/ul/li[3]/text()'</span>)</span><br><span class="line">        <span class="keyword">for</span> time <span class="keyword">in</span> release_time:</span><br><span class="line">            tmp1.append(<span class="string">"release_time"</span>)</span><br><span class="line">            tmp2.append(time[:<span class="number">10</span>])</span><br><span class="line">        <span class="comment">#将两个列表转换为字典，方便插入数据库</span></span><br><span class="line">        result_dict = dict(zip(tmp1, tmp2))</span><br><span class="line">        self.dealData(result_dict)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.get_detail_url(self.base_url, proxys)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">            targetUrl = self.base_url + <span class="string">'&amp;offset='</span> + str((i+<span class="number">1</span>)*<span class="number">30</span>)</span><br><span class="line">            self.get_detail_url(targetUrl, proxys)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    maoyan = Maoyan()</span><br><span class="line">    maoyan.main()</span><br></pre></td></tr></table></figure>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="http://yoursite.com/2017/09/24/爬取猫眼电影数据-1/" data-id="ckbyfke0w000dzbyn1r45xvhd" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    
        
  <nav class="article-nav">
    
      <a href="/2017/09/27/SpringMVC访问静态资源文件/" class="article-nav-link">
        <strong class="article-nav-caption">Newer</strong>
        <div class="article-nav-title">
          
            Spring MVC访问静态资源文件
          
        </div>
      </a>
    
    
      <a href="/2017/09/18/python爬虫如何获取到只需要的数据/" class="article-nav-link">
        <strong class="article-nav-caption">Older</strong>
        <div class="article-nav-title">python爬虫如何获取到只需要的数据</div>
      </a>
    
  </nav>


            

                
                    
                        
                            

</article>
</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 花谢花开</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="花谢花开"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>
<script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/tocbot.min.js"></script>
  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script src="/js/ocean.js"></script>

</body>
</html>